{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd \n",
    "data = pd.read_csv('C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/breast-cancer-wisconsin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Cell_Size</th>\n",
       "      <th>Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        code  Clump_Thickness  Cell_Size  Cell_Shape  Marginal_Adhesion  \\\n",
       "0    1000025                5          1           1                  1   \n",
       "1    1002945                5          4           4                  5   \n",
       "2    1015425                3          1           1                  1   \n",
       "3    1016277                6          8           8                  1   \n",
       "4    1017023                4          1           1                  3   \n",
       "..       ...              ...        ...         ...                ...   \n",
       "678   776715                3          1           1                  1   \n",
       "679   841769                2          1           1                  1   \n",
       "680   888820                5         10          10                  3   \n",
       "681   897471                4          8           6                  4   \n",
       "682   897471                4          8           8                  5   \n",
       "\n",
       "     Single_Epithelial_Cell_Size  Bare_Nuclei  Bland_Chromatin  \\\n",
       "0                              2            1                3   \n",
       "1                              7           10                3   \n",
       "2                              2            2                3   \n",
       "3                              3            4                3   \n",
       "4                              2            1                3   \n",
       "..                           ...          ...              ...   \n",
       "678                            3            2                1   \n",
       "679                            2            1                1   \n",
       "680                            7            3                8   \n",
       "681                            3            4               10   \n",
       "682                            4            5               10   \n",
       "\n",
       "     Normal_Nucleoli  Mitoses  Class  \n",
       "0                  1        1      0  \n",
       "1                  2        1      0  \n",
       "2                  1        1      0  \n",
       "3                  7        1      0  \n",
       "4                  1        1      0  \n",
       "..               ...      ...    ...  \n",
       "678                1        1      0  \n",
       "679                1        1      0  \n",
       "680               10        2      1  \n",
       "681                6        1      1  \n",
       "682                4        1      1  \n",
       "\n",
       "[683 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[data.columns[1:10]]\n",
    "y=data[[\"Class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Cell_Size</th>\n",
       "      <th>Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Clump_Thickness  Cell_Size  Cell_Shape  Marginal_Adhesion  \\\n",
       "0                  5          1           1                  1   \n",
       "1                  5          4           4                  5   \n",
       "2                  3          1           1                  1   \n",
       "3                  6          8           8                  1   \n",
       "4                  4          1           1                  3   \n",
       "..               ...        ...         ...                ...   \n",
       "678                3          1           1                  1   \n",
       "679                2          1           1                  1   \n",
       "680                5         10          10                  3   \n",
       "681                4          8           6                  4   \n",
       "682                4          8           8                  5   \n",
       "\n",
       "     Single_Epithelial_Cell_Size  Bare_Nuclei  Bland_Chromatin  \\\n",
       "0                              2            1                3   \n",
       "1                              7           10                3   \n",
       "2                              2            2                3   \n",
       "3                              3            4                3   \n",
       "4                              2            1                3   \n",
       "..                           ...          ...              ...   \n",
       "678                            3            2                1   \n",
       "679                            2            1                1   \n",
       "680                            7            3                8   \n",
       "681                            3            4               10   \n",
       "682                            4            5               10   \n",
       "\n",
       "     Normal_Nucleoli  Mitoses  \n",
       "0                  1        1  \n",
       "1                  2        1  \n",
       "2                  1        1  \n",
       "3                  7        1  \n",
       "4                  1        1  \n",
       "..               ...      ...  \n",
       "678                1        1  \n",
       "679                1        1  \n",
       "680               10        2  \n",
       "681                6        1  \n",
       "682                4        1  \n",
       "\n",
       "[683 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "..     ...\n",
       "678      0\n",
       "679      0\n",
       "680      1\n",
       "681      1\n",
       "682      1\n",
       "\n",
       "[683 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.22222222, 0.        , 0.        , ..., 0.11111111, 0.11111111,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.22222222, 0.        ,\n",
       "         0.        ],\n",
       "        [0.44444444, 0.        , 0.        , ..., 0.22222222, 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [1.        , 0.        , 0.        , ..., 0.44444444, 0.33333333,\n",
       "         0.        ],\n",
       "        [0.11111111, 0.        , 0.        , ..., 0.11111111, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.11111111, 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.44444444, 0.11111111, 0.11111111, ..., 0.11111111, 0.        ,\n",
       "         0.        ],\n",
       "        [0.33333333, 0.        , 0.        , ..., 0.22222222, 0.11111111,\n",
       "         0.        ],\n",
       "        [0.44444444, 0.11111111, 0.11111111, ..., 0.11111111, 0.11111111,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.66666667, 0.33333333, 0.55555556, ..., 0.33333333, 0.22222222,\n",
       "         0.        ],\n",
       "        [0.22222222, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.11111111, 0.        , 0.        , ..., 0.11111111, 0.        ,\n",
       "         0.        ]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_train, X_scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97265625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[328   5]\n",
      " [  9 170]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train=confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       333\n",
      "           1       0.97      0.95      0.96       179\n",
      "\n",
      "    accuracy                           0.97       512\n",
      "   macro avg       0.97      0.97      0.97       512\n",
      "weighted avg       0.97      0.97      0.97       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_train=classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  2  58]]\n"
     ]
    }
   ],
   "source": [
    "confusion_test=confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬:\\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       111\n",
      "           1       0.92      0.97      0.94        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_test=classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'C': 10}\n",
      "Best Score: 0.9726\n",
      "TestSet Score: 0.9591\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=100,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021AEAB03608>})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "param_distribs={'C': randint(low=0.001, high=100)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(LogisticRegression(), param_distributions=param_distribs, n_iter=100, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'C': 12}\n",
      "Best Score: 0.9745\n",
      "Test Score: 0.9591\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(random_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(random_search.best_score_))\n",
    "print(\"Test Score: {:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Section 2. k-최근접 이웃법 KNN\n",
    "## part1. 분류\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model=KNeighborsClassifier()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[331   2]\n",
      " [  6 173]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train = confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)\n",
    "# 결과값을 보면 정상 0, 중 2명 오분류 환자 1 중 6명 오분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       333\n",
      "           1       0.99      0.97      0.98       179\n",
      "\n",
      "    accuracy                           0.98       512\n",
      "   macro avg       0.99      0.98      0.98       512\n",
      "weighted avg       0.98      0.98      0.98       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_train=classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532163742690059"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  3  57]]\n"
     ]
    }
   ],
   "source": [
    "confusion_test=confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬:\\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       111\n",
      "           1       0.92      0.95      0.93        60\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.95      0.95      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트데이터셋의 평가지표 확인 \n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_test=classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'n_neighbors': 3}\n",
      "Best Score: 0.9824\n",
      "TestSet Score: 0.9532\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(), n_iter=20,\n",
       "                   param_distributions={'n_neighbors': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021AEAC3AC08>})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search \n",
    "from scipy.stats import randint\n",
    "param_distribs = {'n_neighbors': randint(low=1, high=20)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(KNeighborsClassifier(), param_distributions=param_distribs, n_iter=20, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'n_neighbors': 3}\n",
      "Best Score: 0.9824\n",
      "TestSet Score: 0.9532\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(random_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN\n",
    "## part2. 회귀\n",
    "data2=pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/house_price.csv\", encoding=\"utf-8\")\n",
    "X=data2[data2.columns[1:5]]\n",
    "y=data2[[\"house_value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_age</th>\n",
       "      <th>income</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>households</th>\n",
       "      <th>rooms</th>\n",
       "      <th>house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>6.7770</td>\n",
       "      <td>0.141112</td>\n",
       "      <td>2.442244</td>\n",
       "      <td>8.103960</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>6.0199</td>\n",
       "      <td>0.160984</td>\n",
       "      <td>2.726688</td>\n",
       "      <td>5.752412</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>5.1155</td>\n",
       "      <td>0.249061</td>\n",
       "      <td>1.902676</td>\n",
       "      <td>3.888078</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>4.7109</td>\n",
       "      <td>0.231383</td>\n",
       "      <td>1.913669</td>\n",
       "      <td>4.508393</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>4.5625</td>\n",
       "      <td>0.255583</td>\n",
       "      <td>3.092664</td>\n",
       "      <td>4.667954</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housing_age  income  bedrooms  households     rooms  house_value\n",
       "0           23  6.7770  0.141112    2.442244  8.103960       500000\n",
       "1           49  6.0199  0.160984    2.726688  5.752412       500000\n",
       "2           35  5.1155  0.249061    1.902676  3.888078       500000\n",
       "3           32  4.7109  0.231383    1.913669  4.508393       500000\n",
       "4           21  4.5625  0.255583    3.092664  4.667954       500000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>households</th>\n",
       "      <th>rooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.7770</td>\n",
       "      <td>0.141112</td>\n",
       "      <td>2.442244</td>\n",
       "      <td>8.103960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0199</td>\n",
       "      <td>0.160984</td>\n",
       "      <td>2.726688</td>\n",
       "      <td>5.752412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1155</td>\n",
       "      <td>0.249061</td>\n",
       "      <td>1.902676</td>\n",
       "      <td>3.888078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7109</td>\n",
       "      <td>0.231383</td>\n",
       "      <td>1.913669</td>\n",
       "      <td>4.508393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5625</td>\n",
       "      <td>0.255583</td>\n",
       "      <td>3.092664</td>\n",
       "      <td>4.667954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17684</th>\n",
       "      <td>2.3013</td>\n",
       "      <td>0.214583</td>\n",
       "      <td>2.748299</td>\n",
       "      <td>4.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17685</th>\n",
       "      <td>2.6750</td>\n",
       "      <td>0.246622</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>4.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17686</th>\n",
       "      <td>2.3667</td>\n",
       "      <td>0.340771</td>\n",
       "      <td>1.876812</td>\n",
       "      <td>3.572464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17687</th>\n",
       "      <td>2.1000</td>\n",
       "      <td>0.386107</td>\n",
       "      <td>2.987805</td>\n",
       "      <td>3.774390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17688</th>\n",
       "      <td>1.6607</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>2.236842</td>\n",
       "      <td>6.710526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       income  bedrooms  households     rooms\n",
       "0      6.7770  0.141112    2.442244  8.103960\n",
       "1      6.0199  0.160984    2.726688  5.752412\n",
       "2      5.1155  0.249061    1.902676  3.888078\n",
       "3      4.7109  0.231383    1.913669  4.508393\n",
       "4      4.5625  0.255583    3.092664  4.667954\n",
       "...       ...       ...         ...       ...\n",
       "17684  2.3013  0.214583    2.748299  4.897959\n",
       "17685  2.6750  0.246622    3.428571  4.698413\n",
       "17686  2.3667  0.340771    1.876812  3.572464\n",
       "17687  2.1000  0.386107    2.987805  3.774390\n",
       "17688  1.6607  0.286275    2.236842  6.710526\n",
       "\n",
       "[17689 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋과 test 데이터셋을 나눠서 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 방법은 minmax사용하여 훈련데이터셋과 테스트데이터셋의 특성치 X 자료들을 반환한다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16562473, 0.21462821, 0.52074074, 0.44856746],\n",
       "       [0.37212937, 0.17975658, 0.32454019, 0.44769165],\n",
       "       [0.57311602, 0.13685236, 0.3616678 , 0.47640399],\n",
       "       ...,\n",
       "       [0.23197882, 0.3539297 , 0.55216706, 0.27983322],\n",
       "       [0.4880922 , 0.19402626, 0.24817999, 0.43532745],\n",
       "       [0.21204389, 0.23569145, 0.29933466, 0.31673877]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>households</th>\n",
       "      <th>rooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17235</th>\n",
       "      <td>2.0577</td>\n",
       "      <td>0.185449</td>\n",
       "      <td>3.945455</td>\n",
       "      <td>6.372727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14220</th>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.171566</td>\n",
       "      <td>2.741497</td>\n",
       "      <td>6.363946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>5.8904</td>\n",
       "      <td>0.154485</td>\n",
       "      <td>2.969325</td>\n",
       "      <td>6.651840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15279</th>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.241460</td>\n",
       "      <td>3.257256</td>\n",
       "      <td>4.518470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14727</th>\n",
       "      <td>2.7143</td>\n",
       "      <td>0.194977</td>\n",
       "      <td>2.679287</td>\n",
       "      <td>6.385301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>3.0806</td>\n",
       "      <td>0.236803</td>\n",
       "      <td>3.984340</td>\n",
       "      <td>4.534676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>2.2019</td>\n",
       "      <td>0.265491</td>\n",
       "      <td>4.460648</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>2.6818</td>\n",
       "      <td>0.240909</td>\n",
       "      <td>4.138298</td>\n",
       "      <td>4.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>5.0907</td>\n",
       "      <td>0.177247</td>\n",
       "      <td>2.272923</td>\n",
       "      <td>6.239971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>2.4943</td>\n",
       "      <td>0.193835</td>\n",
       "      <td>2.586826</td>\n",
       "      <td>5.050898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13266 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       income  bedrooms  households     rooms\n",
       "17235  2.0577  0.185449    3.945455  6.372727\n",
       "14220  4.0000  0.171566    2.741497  6.363946\n",
       "3280   5.8904  0.154485    2.969325  6.651840\n",
       "15279  0.9393  0.241460    3.257256  4.518470\n",
       "14727  2.7143  0.194977    2.679287  6.385301\n",
       "...       ...       ...         ...       ...\n",
       "11284  3.0806  0.236803    3.984340  4.534676\n",
       "11964  2.2019  0.265491    4.460648  4.333333\n",
       "5390   2.6818  0.240909    4.138298  4.680851\n",
       "860    5.0907  0.177247    2.272923  6.239971\n",
       "15795  2.4943  0.193835    2.586826  5.050898\n",
       "\n",
       "[13266 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6804607237174459"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 기본모델 적용 model에 할당 -> 훈련 fit  -> 예측 predict -> 성능 정확도 score\n",
    "## 회귀에서 정확도 R**2이다. 결정계수이고 0~1사의 값을 가지고 높수록 설명력 높다. 실제 y갑과 예측 y값이 일치한다. \n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model=KNeighborsRegressor()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16562473, 0.21462821, 0.52074074, 0.44856746],\n",
       "       [0.37212937, 0.17975658, 0.32454019, 0.44769165],\n",
       "       [0.57311602, 0.13685236, 0.3616678 , 0.47640399],\n",
       "       ...,\n",
       "       [0.23197882, 0.3539297 , 0.55216706, 0.27983322],\n",
       "       [0.4880922 , 0.19402626, 0.24817999, 0.43532745],\n",
       "       [0.21204389, 0.23569145, 0.29933466, 0.31673877]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5541889571372401"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 테스트 데이터도 55%로 나쁘지는 않지만 훈련데이터 보다 13%정도 낮아서 다소 훈련데이터에 과대적합된 K값일 수도 있다.\n",
    "\n",
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 RMSE: 53952.69804097723\n",
      "테스트데이터 RMSE: 63831.91662964773\n"
     ]
    }
   ],
   "source": [
    "## RMSE(Root Mean Squared Error), 오차는 작을수록 좋은 모델이다. 훈련 53952, 테스트데이터 63831이므로 훈련데이터에 좀 더 적합되었음\n",
    "\n",
    "import numpy as np \n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE:\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "             param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "\n",
    "param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(KNeighborsRegressor(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'n_neighbors': 11}\n",
      "Best Score: 0.5638272489240468\n",
      "TestSet Score: 0.5880\n"
     ]
    }
   ],
   "source": [
    "## 분석결과 k=11일때 최적의 하이퍼파라미터이고 훈련데이터 정확도 56.4% 테스트데이터 정확도 58.8% \n",
    "## K 값이 더 커진 것은 다른 데이터에도 잘 맞는 일반화의 가능성이 더 높아진 모델임을 의미\n",
    "\n",
    "print(\"Best Parameter: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score: {}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(), n_iter=20,\n",
       "                   param_distributions={'n_neighbors': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021AEAC3A488>})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "\n",
    "param_distribs = {'n_neighbors': randint(low=1, high=20)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(KNeighborsRegressor(), param_distributions=param_distribs, n_iter=20, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'n_neighbors': 19}\n",
      "Best Score: 0.5776685542345874\n",
      "TestSet Score: 0.6004\n"
     ]
    }
   ],
   "source": [
    "## k = 19일때 훈련데이터의 정확도 57.8% 테스트데이터의 정확도 60.04%으로 나왔다. k의 크기를 더 키워야지 더 좋은 모델이 찾아지는것으로 \n",
    "## 확인된다.\n",
    "\n",
    "print(\"Best Parameter: {}\".format(random_search.best_params_))\n",
    "print(\"Best Score: {}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966796875"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Section03 나이브 베이즈 \n",
    "## 나이브베이즈란 조건부 확률과 베이즈 정리를 이용한 알고리즘이다. 나이브란 예측에 사용되는 특성치X 가 상호 독립적이라는 가정하에 \n",
    "## 확률 계산을 단순화하기 위해 나이브(naive, 단순 순진한 가정)라고 이름이 붙여진 것이다.\n",
    "\n",
    "## 하이퍼 파라미터는 var_smopthing이다. 안정적인 연산을 위해 분산에 더해지는 모든 특성치의 최대 분산 비율\n",
    "data = pd.read_csv('C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/breast-cancer-wisconsin.csv')\n",
    "X=data[data.columns[1:10]]\n",
    "y=data[[\"Class\"]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model=GaussianNB()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[319  14]\n",
      " [  3 176]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train = confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       333\n",
      "           1       0.93      0.98      0.95       179\n",
      "\n",
      "    accuracy                           0.97       512\n",
      "   macro avg       0.96      0.97      0.96       512\n",
      "weighted avg       0.97      0.97      0.97       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_train = classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  2  58]]\n"
     ]
    }
   ],
   "source": [
    "confusion_test=confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬:\\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       111\n",
      "           1       0.92      0.97      0.94        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_test=classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "## 하이퍼 파라미터중 var_smoothing을 0~10까지 총 10개로 설정\n",
    "\n",
    "param_grid={'var_smoothing': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(GaussianNB(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: {'var_smoothing': 0}\n",
      "Best Score: 0.9649\n",
      "TestSet Score: 0.9591\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GaussianNB(), n_iter=100,\n",
       "                   param_distributions={'var_smoothing': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021AEBC62088>})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "## 0~20 까지중 랜덤으로 100번 수행\n",
    "from scipy.stats import randint\n",
    "param_distribs = {'var_smoothing': randint(low=0, high=20)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(GaussianNB(), param_distributions=param_distribs, n_iter=100, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'var_smoothing': 0}\n",
      "Best Score: 0.9649\n",
      "TestSet Score: 0.9591\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(random_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(random_search.score(X_scaled_test, y_test)))\n",
    "\n",
    "## 가우시안 나이브 베이즈의 분류 모델은 기본모델, 그리드탐색, 랜덤탐색에서 유사한 결과를 보인다. \n",
    "## 나이브 베이즈 모델은 성능이 좋은 모델은 아니다. 그러나 다른 모델과의 성능 비교를 위한 기저모델로 많이 활용되므로 알아둬야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5455724466331763"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part2. 회귀 Regression\n",
    "## house_price.csv 파일 가져오고 분류\n",
    "data2=pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/house_price.csv\", encoding=\"utf-8\")\n",
    "X=data2[data2.columns[1:5]]\n",
    "y=data2[[\"house_value\"]]\n",
    "\n",
    "## train 데이터셋과 test 데이터셋을 나눠서 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "## 정규화 방법은 minmax사용하여 훈련데이터셋과 테스트데이터셋의 특성치 X 자료들을 반환한다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n",
    "## 훈련데이터의 정확도는 54.6%이다.\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "model=BayesianRidge()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5626859871488648"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 정확도는 56.27%이다.\n",
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 RMSE: 64340.34302948542\n",
      "테스트데이터 RMSE: 63220.68115643447\n"
     ]
    }
   ],
   "source": [
    "## RMSE (Root Mean Squared Error)\n",
    "## 오차는 훈련데이터 64340 테스트데이터는 63220 \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE:\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=BayesianRidge(),\n",
       "             param_grid={'alpha_1': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                     2, 3, 4],\n",
       "                         'lambda_1': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                      2, 3, 4]})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "param_grid={'alpha_1': [1e-06, 1e-05, 1e-04, 1e-03, 1e-02, 1e-01, 1, 2, 3, 4], 'lambda_1': [1e-06, 1e-05, 1e-04, 1e-03, 1e-02, 1e-01, 1, 2, 3, 4]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(BayesianRidge(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'alpha_1': 4, 'lambda_1': 1e-06}\n",
      "Best Score: 0.5452\n",
      "TestSet Score: 0.5627\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=BayesianRidge(), n_iter=50,\n",
       "                   param_distributions={'alpha_1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021AEAC8E348>,\n",
       "                                        'lambda_1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021AEBCC9E88>})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "\n",
    "param_distribs = {'alpha_1': randint(low=1e-06, high=10), 'lambda_1': randint(low=1e-06, high=10)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(BayesianRidge(), param_distribs, n_iter=50, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'alpha_1': 9, 'lambda_1': 0}\n",
      "Best Score: 0.5452\n",
      "TestSet Score: 0.5627\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(random_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(random_search.score(X_scaled_test, y_test)))\n",
    "## 베이지안릿지모델은 회귀모델에서 자주 사용하는 알고리즘은 아니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section04 인공신경망\n",
    "## 인공신경망은 인간의 뉴런구조와 활성화 작동원리를 근간으로 input(자극)과 output(반응)과의 연관을 구현한 알고리즘 \n",
    "## 전통적인 알고리즘과 가장 큰 차이는 중간에 은닉층(hidden layer)과 노드(nodes)들을 깊고(deep) 넓게(wide) 두어 특성치로부터 \n",
    "## 분류와 회귀를 더 잘할 수 있도록 특징추출 및  분류 단계를 확장하는 역할을 할 수 있도록 한 모델\n",
    "## 인공신경망의 기초모델은 다층퍼셉트론을 수행 \n",
    "## 입력층과 출력층은 각각 특성치(X)와 레이블(y)을 말한다. 이 중간에 은닉층을 몇 개로 둘 것인지, 각 은닉층에 노드를 얼마나 둘 것인가\n",
    "## 핵심 파라미터이다. 이외에도 학습율, 활성화함수는 분류 혹은 회귀를 선형 혹은 로지스틱, relu등 분류 구분자의 특성을 말한다. \n",
    "\n",
    "data = pd.read_csv('C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/breast-cancer-wisconsin.csv')\n",
    "X=data[data.columns[1:10]]\n",
    "y=data[[\"Class\"]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model=MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974609375"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model=MLPClassifier()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[328   5]\n",
      " [  8 171]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train=confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       333\n",
      "           1       0.97      0.96      0.96       179\n",
      "\n",
      "    accuracy                           0.97       512\n",
      "   macro avg       0.97      0.97      0.97       512\n",
      "weighted avg       0.97      0.97      0.97       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_train=classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  2  58]]\n"
     ]
    }
   ],
   "source": [
    "confusion_test=confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬:\\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       111\n",
      "           1       0.92      0.97      0.94        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_test=classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'hidden_layer_sizes': [10, 30, 50, 100],\n",
       "                         'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "##  hidden_layer_sizes(은닉층수), solver(옵티마이저), activation(활성화함수) 3가지 튜닝해보자\n",
    "## 은닉층 -10, 30, 50, 100 옵티마이저 -sgd, adm 활성화함수 -tanh, relu  의 16가지 조합으로 분석\n",
    "param_grid={'hidden_layer_sizes':[10, 30, 50, 100], 'solver':['sgd', 'adam'], 'activation':['tanh', 'relu']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(MLPClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'activation': 'relu', 'hidden_layer_sizes': 30, 'solver': 'adam'}\n",
      "Best Score:0.9746\n",
      "TestSet Score:0.9591\n"
     ]
    }
   ],
   "source": [
    "## 최적의 하이퍼파라미터는 relu, 30, adam 입니다. \n",
    "## 정확도는 97.46%, 테스트데이터의 스코어 95.91%이다.\n",
    "\n",
    "print(\"Best Parameter:{}\".format(grid_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=MLPClassifier(),\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021AEAAA0C08>,\n",
       "                                        'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "## 랜덤탐색을 진행, solver, activation은 동일하게 2가지로 하면서 은닉층수(hidden_layer_sizes) \n",
    "## 10~100사이에서 10번으로 랜덤하게 설정 \n",
    "\n",
    "from scipy.stats import randint\n",
    "param_distribs={'hidden_layer_sizes':randint(low=10, high=100), 'solver':['sgd', 'adam'], 'activation':['tanh', 'relu']}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(MLPClassifier(), param_distributions=param_distribs, n_iter=10, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter:{'activation': 'relu', 'hidden_layer_sizes': 80, 'solver': 'adam'}\n",
      "Best Score:0.9726\n",
      "TestSet:0.9591\n"
     ]
    }
   ],
   "source": [
    "## best parameter relu, 80, adam\n",
    "## 훈련 97.26% 테스트 95.91%\n",
    "print(\"Best parameter:{}\".format(random_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet:{:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.656925617409971"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part2. 회귀(Regression)\n",
    "## house_price.csv 파일 가져오고 분류\n",
    "data2=pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/house_price.csv\", encoding=\"utf-8\")\n",
    "X=data2[data2.columns[1:5]]\n",
    "y=data2[[\"house_value\"]]\n",
    "\n",
    "## train 데이터셋과 test 데이터셋을 나눠서 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "## 정규화 방법은 minmax사용하여 훈련데이터셋과 테스트데이터셋의 특성치 X 자료들을 반환한다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "model=MLPRegressor()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.6153982713449553"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)\n",
    "## 훈련데이터, 테스트데이터 둘 다 이상하다. -262.54%는 말이 안된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 RMSE:182519.43147647224\n",
      "테스트 데이터 RMSE:181777.67607731136\n"
     ]
    }
   ],
   "source": [
    "## RMSE (Root Mean Squared Error)\n",
    "import numpy as np \n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련 데이터 RMSE:{}\".format(np.sqrt(MSE_train)))\n",
    "print(\"테스트 데이터 RMSE:{}\".format(np.sqrt(MSE_test)))\n",
    "## 오차가 크다 좀 이상하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.566197903746314"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 튜닝 모델 \n",
    "## 그리드 탐색과 랜덤탐색은 하이퍼파라미터가 매우 다양하여 최적 조합을 찾는 것이 힘들다. \n",
    "## 따라서 은닉층을 3개로 두어 각가 64개의 노드를 구성하는 조금 깊은 모델을 만들어 보자 \n",
    "## hidden_layer_sizes(64, 64, 64), 활성화 함수는 activation=\"relu\"\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "model = MLPRegressor(hidden_layer_sizes=(64, 64, 64), activation=\"relu\", random_state=1, max_iter=2000)\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)\n",
    "## 56.62%로 조금 전 보다 훨씬 좋다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.584086684313508"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)\n",
    "## 테스트 데이터도 58.41%로 훨씬 좋게 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 RMSE:62863.255358058195\n",
      "테스트 데이터 RMSE:61654.37310884089\n"
     ]
    }
   ],
   "source": [
    "## RMSE(Root Mean Squared Error)\n",
    "import numpy as np \n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련 데이터 RMSE:{}\".format(np.sqrt(MSE_train)))\n",
    "print(\"테스트 데이터 RMSE:{}\".format(np.sqrt(MSE_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 인공신경망 종합정리\n",
    "## 다층퍼셉트론은 딥러닝의 구조와 동일하나 하이퍼파라미터가 매우 많고 모델에 대한 깊은 이해가 있어야 한다.\n",
    "## 실제 다층퍼셉트론을 사용하기보다는 딥러닝을 활용해서 분류와 회귀의 문제를 수행\n",
    "## 은닉층, 노드의 수, 활성화함수 등을 다양하게 조합하여 수행해야지 좋은 선응을 가져오기 가능하다.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 05 서포트 벡터머신\n",
    "data = pd.read_csv('C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/breast-cancer-wisconsin.csv')\n",
    "X=data[data.columns[1:10]]\n",
    "y=data[[\"Class\"]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984375"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model=SVC()\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[329   4]\n",
      " [  4 175]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train = confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       333\n",
      "           1       0.98      0.98      0.98       179\n",
      "\n",
      "    accuracy                           0.98       512\n",
      "   macro avg       0.98      0.98      0.98       512\n",
      "weighted avg       0.98      0.98      0.98       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_train=classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "confusion_test = confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬:\\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트 :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       111\n",
      "           1       0.92      0.98      0.95        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.97      0.96       171\n",
      "weighted avg       0.97      0.96      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "cfreport_test=classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트 :\\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid=[{'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'kernel': ['linear']}])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "## 하이퍼파라미터 중 kernel을 rbf와 linear로 하면서 C는 0.001, 0.01, 0.1, 1, 10, 100 \n",
    "## gamma는 0.001, 0.01, 0.1, 1, 10, 100 이렇게 조합하면서 그리드탐색을 진행한다.\n",
    "param_grid=[{'kernel':['rbf'], 'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "            {'kernel':['linear'], 'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Score: 0.9745669141442985\n",
      "TestSet Score: 0.9591\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score: {}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 333, in _dense_fit\n",
      "    random_seed=random_seed,\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.96282125 0.95309347 0.89061489 0.90034266 0.87690843 0.91795165\n",
      " 0.9394822  0.86325909 0.93752142 0.89061489 0.88867314 0.85933752\n",
      " 0.91208833 0.9394822  0.87886922 0.92967828 0.93359985 0.86325909\n",
      " 0.9394822  0.96089853 0.95893775 0.86908433 0.95309347 0.90034266\n",
      " 0.923834   0.87298686 0.91012755 0.94530744 0.65039025 0.87298686\n",
      " 0.89061489 0.87690843 0.91208833 0.96282125 0.86325909 0.88671235\n",
      " 0.89061489 0.86714259 0.90816676 0.90230345        nan 0.91208833\n",
      " 0.90230345 0.89061489 0.88475157 0.90816676 0.90034266 0.86714259\n",
      " 0.94726823 0.87104512 0.86325909 0.86714259 0.88671235 0.93163906\n",
      " 0.88867314 0.91012755 0.95309347 0.93359985 0.87690843 0.95309347\n",
      " 0.90424519 0.91012755 0.87690843 0.89061489 0.86325909 0.89840091\n",
      " 0.96089853 0.89061489 0.89061489 0.94142395 0.94530744 0.96480107\n",
      " 0.91208833 0.87690843 0.86908433 0.86714259 0.94726823 0.94142395\n",
      " 0.86714259 0.86325909 0.94142395 0.88279079 0.88279079 0.90230345\n",
      " 0.91012755 0.95697697 0.923834   0.95309347        nan 0.87886922\n",
      " 0.87298686 0.86325909 0.87298686 0.88671235 0.95309347 0.95309347\n",
      " 0.92967828 0.86325909 0.95309347 0.86908433]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=SVC(), n_iter=100,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000028A082A1E08>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000028A082A1F08>,\n",
       "                                        'kernel': ['rbf']})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "## kernel 'rbf', C 0.001~100, gamma 0.001~100 에서 100번 무작위 모델 수행\n",
    "\n",
    "from scipy.stats import randint\n",
    "param_distribs={'kernel':['rbf'], 'C':randint(low=0.001, high=100), 'gamma':randint(low=0, high=100)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(SVC(), param_distributions=param_distribs, n_iter=100, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'C': 41, 'gamma': 5, 'kernel': 'rbf'}\n",
      "Best Score: 0.9648\n",
      "TestSet Score: 0.9649\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(random_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(random_search.score(X_scaled_test, y_test)))\n",
    "## 서포트벡터머신은 다른 알고리즘에 비해 kernel 종류, C와 gamma 등 하이퍼파라미터가 다양하다. \n",
    "## 그만큼 모델의 유연성이 뛰어나다. 그러나 이해가 깊어야 모델을 유연하게 다룰 수 있다. \n",
    "## 그러나 대규모 데이터에는 느린 학습속도를 보인다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part2. 회귀(Regression)\n",
    "## 알고리즘은 SVC가 아닌 SVR을 이용 kernel의 종류인 linear, poly, rbf, sigmoid, precomputed, \n",
    "## kernel는 poly로 설정한다. \n",
    "data2=pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/house_price.csv\", encoding=\"utf-8\")\n",
    "X=data2[data2.columns[1:5]]\n",
    "y=data2[[\"house_value\"]]\n",
    "\n",
    "## train 데이터셋과 test 데이터셋을 나눠서 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "## 정규화 방법은 minmax사용하여 훈련데이터셋과 테스트데이터셋의 특성치 X 자료들을 반환한다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4517702565282383"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 훈련데이터의 정확도는 45.2%\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "model=SVR(kernel='poly')\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4699770809619137"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 테스트데이터에 예측값 저장하고 정확도 확인하면 47%로 나온다. 훈련데이터, 테스트데이터의 정확도는 \n",
    "## 10% 정도 낮다.\n",
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 RMSE: 70669.55244251259\n",
      "테스트 데이터 RMSE: 69600.08959938577\n"
     ]
    }
   ],
   "source": [
    "## RMSE (Root Mean Squared Error)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련 데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트 데이터 RMSE:\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(kernel='poly'),\n",
       "             param_grid={'C': [10], 'gamma': [0.01, 0.1, 1, 10],\n",
       "                         'kernel': ['poly']})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "param_grid={'kernel':['poly'], 'C': [10], 'gamma': [0.01, 0.1, 1, 10]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(SVR(kernel='poly'), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'C': 10, 'gamma': 10, 'kernel': 'poly'}\n",
      "Best Score: 0.4888\n",
      "TestSet Score: 0.5092\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Search \n",
    "\n",
    "param_distribs={'kernel':['poly'], 'C': randint(low=0.01, high=10), 'gamma': randint(low=0.01, high=10)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(SVR(kernel='poly'),param_distributions=param_distribs, n_iter=20, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameter: {}\".format(random_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 의사결정나무\n",
    "import pandas as pd \n",
    "data = pd.read_csv('C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/breast-cancer-wisconsin.csv')\n",
    "X=data[data.columns[1:10]]\n",
    "y=data[[\"Class\"]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 정확도 100%? 엄청 높다.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[333   0]\n",
      " [  0 179]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train=confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       333\n",
      "           1       1.00      1.00      1.00       179\n",
      "\n",
      "    accuracy                           1.00       512\n",
      "   macro avg       1.00      1.00      1.00       512\n",
      "weighted avg       1.00      1.00      1.00       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_train=classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 이 결과로 미루어보아 훈련데이터에 과대적합된 거 같다.\n",
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬:\n",
      " [[105   6]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "## 정상 중 6명, 환자 중 2명 오분류, \n",
    "confusion_test=confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬:\\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       111\n",
      "           1       0.91      0.98      0.94        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 테스트데이터셋의 평가 지표는 0.94~0.96수준 \n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_test=classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': range(2, 20, 2),\n",
       "                         'min_samples_leaf': range(1, 50, 2)})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "\n",
    "param_grid={'max_depth':range(2,20,2), 'min_samples_leaf':range(1,50,2)}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'max_depth': 6, 'min_samples_leaf': 1}\n",
      "Best Score: 0.9648\n",
      "TestSet Score: 0.9357\n"
     ]
    }
   ],
   "source": [
    "## max_depth:6, min_samples_leaf:1 일대 최적의 조합 훈련데이터의 정확도는 96.5%, 테스트 데이터 94.2%\n",
    "print(\"Best Parameter: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_iter=20,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021908809C48>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021908808B08>})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "## max_depth 1~20, min_samples_leaf 1~50사이에서 무작위로 20개 n_iter=20\n",
    "from scipy.stats import randint\n",
    "param_distribs = {'max_depth':randint(low=1, high=20), 'min_samples_leaf':randint(low=1, high=50)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(DecisionTreeClassifier(), param_distributions=param_distribs, n_iter=20, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'max_depth': 14, 'min_samples_leaf': 10}\n",
      "Best Score: 0.9453\n",
      "TestSet Score: 0.9123\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(random_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score: {:.4f}\".format(random_search.score(X_scaled_test, y_test)))\n",
    "\n",
    "## 의사결정나무는 결과들을 봐왔듯이 학습데이터에 매우 과적합되는 경향이 있다. 100%의 분류 예측이 이를 \n",
    "## 보여준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part2. 회귀(Regression)\n",
    "\n",
    "data2=pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/house_price.csv\", encoding=\"utf-8\")\n",
    "X=data2[data2.columns[1:5]]\n",
    "y=data2[[\"house_value\"]]\n",
    "\n",
    "## train 데이터셋과 test 데이터셋을 나눠서 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "## 정규화 방법은 minmax사용하여 훈련데이터셋과 테스트데이터셋의 특성치 X 자료들을 반환한다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model=DecisionTreeRegressor()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22253575185564411"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 RMSE: 0.0\n",
      "테스트 데이터 RMSE: 84295.16933455101\n"
     ]
    }
   ],
   "source": [
    "## RMSE (Root Mean Squared Error)\n",
    "## 훈련 데이터 RMSE가 0이고 테스트 데이터 84295이므로 이 결과로 보아서 훈련데이터에 과대하게 fitted된 모델\n",
    "## 결과임을 알 수 있다.\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련 데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트 데이터 RMSE:\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': range(2, 20, 2),\n",
       "                         'min_samples_leaf': range(1, 50, 2)})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "param_grid={'max_depth':range(2,20,2), 'min_samples_leaf':range(1,50,2)}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'max_depth': 8, 'min_samples_leaf': 49}\n",
      "Best Score:0.5592\n",
      "TestSet Score:0.5770\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter:{}\".format(grid_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeRegressor(), n_iter=20,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021908468C08>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002190881D188>})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "param_distribs = {'max_depth': randint(low=1, high=20), 'min_samples_leaf': randint(low=1, high=50)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(DecisionTreeRegressor(), param_distributions=param_distribs, n_iter=20, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'max_depth': 15, 'min_samples_leaf': 49}\n",
      "Best Score:0.5586\n",
      "TestSet Score:0.5767\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter:{}\".format(random_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(random_search.score(X_scaled_test, y_test)))\n",
    "\n",
    "## 기본모델에선 과대적합, 다만 적절한 하이퍼 파라미터를 찾으면 테스트셋의 결과가 양호하게 나와 일반화 \n",
    "## 가능성이 높다. 디폴트 모델이 아닌 데이터에 적절한 설정을 찾아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section07 랜덤포레스트\n",
    "## 랜덤포레스트 알고리즘은 학습 데이터로 여러 의사결정트리를 구성하여 분석하고 이를 종합하는 앙상블 기법이다.\n",
    "## 랜덤포레스트는 한 마디로 의사결정나무 수십 수백개가 예측한 분류 혹은 회귀값을 평균낸 모델이다.\n",
    "## 학습데이터를 무작위로 샘플링해서 다수의 의사결정 트리 분석하기 때문 랜덤+포레스트라 하는 것이다.\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 7.3 분석코드\n",
    "## Part1. 분류(Classification)\n",
    "\n",
    "import pandas as pd \n",
    "data = pd.read_csv('C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/breast-cancer-wisconsin.csv')\n",
    "X=data[data.columns[1:10]]\n",
    "y=data[[\"Class\"]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[333   0]\n",
      " [  0 179]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train=confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       333\n",
      "           1       1.00      1.00      1.00       179\n",
      "\n",
      "    accuracy                           1.00       512\n",
      "   macro avg       1.00      1.00      1.00       512\n",
      "weighted avg       1.00      1.00      1.00       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_train=classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': range(100, 1000, 100)})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "param_grid={'n_estimators':range(100, 1000, 100), 'max_features':['auto', 'sqrt','log2']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Best Score: 0.9765\n",
      "TestSet: 0.9649\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score: {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet: {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=20,\n",
       "                   param_distributions={'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000219087FC748>})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "## n_estimators 100~1000 max_features 세 가지 방법 사이에서 무작위로 20개의 모델 n_iter=20 \n",
    "\n",
    "from scipy.stats import randint\n",
    "param_distribs = {'n_estimators': randint(low=100, high=1000), 'max_features': ['auto', 'sqrt', 'log2']}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_distribs, n_iter=20, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'max_features': 'log2', 'n_estimators': 195}\n",
      "Best Score:0.9765\n",
      "TestSet Score:0.9708\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter:{}\".format(random_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9376381392218429"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part2. 회귀(Regression)\n",
    "\n",
    "import pandas as pd\n",
    "data2=pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/house_price.csv\", encoding=\"utf-8\")\n",
    "X=data2[data2.columns[1:5]]\n",
    "y=data2[[\"house_value\"]]\n",
    "\n",
    "## train 데이터셋과 test 데이터셋을 나눠서 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "## 정규화 방법은 minmax사용하여 훈련데이터셋과 테스트데이터셋의 특성치 X 자료들을 반환한다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model=RandomForestRegressor()\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5828108987548738"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 RMSE 23834.74866076614\n",
      "테스트데이터 RMSE 61748.86098514909\n"
     ]
    }
   ],
   "source": [
    "# RMSE (Root Mean Squared Error)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "\n",
    "print(\"훈련데이터 RMSE\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE\",np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': range(100, 500, 100)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "param_grid={'n_estimators': range(100, 500, 100), 'max_features': ['auto', 'sqrt', 'log2']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(RandomForestRegressor(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'max_features': 'sqrt', 'n_estimators': 400}\n",
      "Best Score:0.5683\n",
      "TestSet Score:0.5934\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter:{}\".format(grid_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "65 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "65 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 459, in fit\n",
      "    for i, t in enumerate(trees)\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 211, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1320, in fit\n",
      "    X_idx_sorted=X_idx_sorted,\n",
      "  File \"C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 282, in fit\n",
      "    \"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.55822277        nan        nan 0.55946432        nan\n",
      " 0.55946598 0.55812019        nan        nan        nan        nan\n",
      "        nan 0.55745454        nan 0.55713631        nan        nan\n",
      "        nan 0.55969612]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=20,\n",
       "                   param_distributions={'max_features': ['auto', 'sqrtlog2'],\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000017CDE7674C8>})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "from scipy.stats import randint\n",
    "param_distribs={'n_estimators':randint(low=100, high=500), 'max_features':['auto', 'sqrt' 'log2']}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(RandomForestRegressor(), param_distributions=param_distribs, n_iter=20, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'max_features': 'auto', 'n_estimators': 488}\n",
      "Best Score:0.5597\n",
      "TestSet Score:0.5864\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter:{}\".format(random_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(random_search.score(X_scaled_test, y_test)))\n",
    "## 기본 디폴트 모델에서는 과대적합되는 경향을 보였다. 그러나 적절한 모델수와 특성치를 탐색한 결과는 좋은 \n",
    "## 결과를 보여준다. 기분 설정보다느 최적의 하이퍼파라미터를 찾아 회귀문제에 적용하는 것이 적절한 모델이다.\n",
    "## 개별 알고리즘보다 더 좋은 성능을 보이며 다른 앙상블 기법에 비해서 심플하고 강력하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Section08 투표기반 앙상블\n",
    "## 투표기반 앙상블은 여러 분류기를 학습시킨 후 각가의 분류기가 예측하는 레이블 범주가 가장 많이 나오는 범주를 \n",
    "## 예측하는 방법이다. \n",
    "## Part1. 분류 Classification\n",
    "## 강한 학습기 hard learner\n",
    "import pandas as pd \n",
    "data = pd.read_csv('C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/breast-cancer-wisconsin.csv')\n",
    "X=data[data.columns[1:10]]\n",
    "y=data[[\"Class\"]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "logit_model = LogisticRegression(random_state=42)\n",
    "rnf_model = RandomForestClassifier(random_state=42)\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "voting_hard = VotingClassifier(estimators=[('lr', logit_model), ('rf', rnf_model), ('svc', svm_model)],\n",
    "                              voting='hard')\n",
    "voting_hard.fit(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9590643274853801\n",
      "RandomForestClassifier 0.9649122807017544\n",
      "SVC 0.9649122807017544\n",
      "VotingClassifier 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (logit_model, rnf_model, svm_model, voting_hard):\n",
    "    clf.fit(X_scaled_train, y_train.values.ravel())\n",
    "    y_pred = clf.predict(X_scaled_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 분류기 훈련데이터 오차행렬:\n",
      " [[328   5]\n",
      " [  9 170]]\n",
      "로지스틱 분류기 테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  2  58]]\n"
     ]
    }
   ],
   "source": [
    "## 로지스틱 회귀모델의 분류결과\n",
    "from sklearn.metrics import confusion_matrix\n",
    "log_pred_train=logit_model.predict(X_scaled_train)\n",
    "log_confusion_train=confusion_matrix(y_train, log_pred_train)\n",
    "print(\"로지스틱 분류기 훈련데이터 오차행렬:\\n\", log_confusion_train)\n",
    "\n",
    "log_pred_test=logit_model.predict(X_scaled_test)\n",
    "log_confusion_test=confusion_matrix(y_test, log_pred_test)\n",
    "print(\"로지스틱 분류기 테스트데이터 오차행렬:\\n\", log_confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서포트벡터머신 분류기 훈련데이터 오차행렬:\n",
      " [[329   4]\n",
      " [  4 175]]\n",
      "서포트벡터머신 분류기 테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "## 서포트벡터머신의 분류 결과\n",
    "svm_pred_train=svm_model.predict(X_scaled_train)\n",
    "svm_confusion_train=confusion_matrix(y_train, svm_pred_train)\n",
    "print(\"서포트벡터머신 분류기 훈련데이터 오차행렬:\\n\", svm_confusion_train)\n",
    "\n",
    "svm_pred_test=svm_model.predict(X_scaled_test)\n",
    "svm_confusion_test=confusion_matrix(y_test, svm_pred_test)\n",
    "print(\"서포트벡터머신 분류기 테스트데이터 오차행렬:\\n\", svm_confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 분류기 훈련데이터 오차행렬:\n",
      " [[333   0]\n",
      " [  0 179]]\n",
      "랜덤포레스트 분류기 훈련데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "## 랜덤포레스트의 분류 결과 \n",
    "\n",
    "rnd_pred_train=rnf_model.predict(X_scaled_train)\n",
    "rnd_confusion_train=confusion_matrix(y_train, rnd_pred_train)\n",
    "print(\"랜덤포레스트 분류기 훈련데이터 오차행렬:\\n\", rnd_confusion_train)\n",
    "\n",
    "rnd_pred_test=rnf_model.predict(X_scaled_test)\n",
    "rnd_confusion_test=confusion_matrix(y_test, rnd_pred_test)\n",
    "print(\"랜덤포레스트 분류기 훈련데이터 오차행렬:\\n\", rnd_confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "투표기반 앙상블 훈련데이터 오차행렬:\n",
      " [[329   4]\n",
      " [  4 175]]\n",
      "투표기반 앙상블 테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "## 투표기반 앙상블 모델의 분류 결과 \n",
    "voting_hard_pred_train=voting_hard.predict(X_scaled_train)\n",
    "voting_hard_confusion_train=confusion_matrix(y_train, voting_hard_pred_train)\n",
    "print(\"투표기반 앙상블 훈련데이터 오차행렬:\\n\", voting_hard_confusion_train)\n",
    "\n",
    "voting_hard_pred_test=voting_hard.predict(X_scaled_test)\n",
    "voting_hard_confusion_test=confusion_matrix(y_test, voting_hard_pred_test)\n",
    "print(\"투표기반 앙상블 테스트데이터 오차행렬:\\n\", voting_hard_confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(probability=True, random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 약한 학습기 sofr learner\n",
    "\n",
    "logit_model = LogisticRegression(random_state=42)\n",
    "rnf_model = RandomForestClassifier(random_state=42)\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "voting_soft = VotingClassifier(estimators=[('lr', logit_model), ('rf', rnf_model), ('svc', svm_model)]\n",
    "                              , voting ='soft')\n",
    "voting_soft.fit(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9590643274853801\n",
      "RandomForestClassifier 0.9649122807017544\n",
      "SVC 0.9649122807017544\n",
      "VotingClassifier 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (logit_model, rnf_model, svm_model, voting_soft):\n",
    "    clf.fit(X_scaled_train, y_train.values.ravel())\n",
    "    y_pred=clf.predict(X_scaled_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "투표기반 앙상블 훈련데이터 오차행렬:\n",
      " [[330   3]\n",
      " [  3 176]]\n",
      "투표기반 앙상블 테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "voting_soft_pred_train=voting_soft.predict(X_scaled_train)\n",
    "voting_soft_confusion_train=confusion_matrix(y_train, voting_soft_pred_train)\n",
    "print(\"투표기반 앙상블 훈련데이터 오차행렬:\\n\", voting_soft_confusion_train)\n",
    "\n",
    "voting_soft_pred_test=voting_soft.predict(X_scaled_test)\n",
    "voting_soft_confusion_test=confusion_matrix(y_test, voting_soft_pred_test)\n",
    "print(\"투표기반 앙상블 테스트데이터 오차행렬:\\n\", voting_soft_confusion_test)\n",
    "## 앙상블은 일반적으로 좋은 개별 알고리즘을 조합하면 그보다 좀 더 나은 결과를 보인다.\n",
    "## 또한 범주(hard)보다는 확률(soft)방식이 다소 정확도가 높은 것으로 알려져있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part2. 회귀(Regression)\n",
    "import pandas as pd\n",
    "data2=pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/house_price.csv\", encoding=\"utf-8\")\n",
    "X=data2[data2.columns[1:5]]\n",
    "y=data2[[\"house_value\"]]\n",
    "\n",
    "## train 데이터셋과 test 데이터셋을 나눠서 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "## 정규화 방법은 minmax사용하여 훈련데이터셋과 테스트데이터셋의 특성치 X 자료들을 반환한다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('lr', LinearRegression()),\n",
       "                            ('rf', RandomForestRegressor())])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "rnf_model = RandomForestRegressor()\n",
    "\n",
    "voting_regressor = VotingRegressor(estimators=[('lr', linear_model), ('rf', rnf_model)])\n",
    "voting_regressor.fit(X_scaled_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7965479261463408"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train=voting_regressor.predict(X_scaled_train)\n",
    "voting_regressor.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5935337291360735"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=voting_regressor.predict(X_scaled_test)\n",
    "voting_regressor.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 RMSE:43050.88706123201\n",
      "테스트 데이터 RMSE:60950.14321685311\n"
     ]
    }
   ],
   "source": [
    "## RMSE (Root Mean Squared Error)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련 데이터 RMSE:{}\".format(np.sqrt(MSE_train)))\n",
    "print(\"테스트 데이터 RMSE:{}\".format(np.sqrt(MSE_test)))\n",
    "## 회귀문제에서 투표기반 앙상블로 2개 알고리즘만을 조합하였음에도 정확도가 개별 알고리즘을 적용할 때보다 \n",
    "## 테스트데이터에서 2~3%높게 나타났다. 이는 절대 낮은게 아니다. 개별 알고리즘에서 가장 좋은 하이퍼 파라미터\n",
    "## 찾아 설정한다면 더 좋은 결과도 가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section09 앙상블 배깅(Bagging)\n",
    "## 여러개의 부트스트랩 데이터를 생성하고 각 부트스트랩 데이터에 하나 혹은 여러 알고리즘을 학습시킨 후 \n",
    "## 산출된 결과 중 투표 방식에 의해 최종 결과를 선정하는 알고리즘이다.\n",
    "## 핵심 파라미터는 n_estimator이다\n",
    "\n",
    "import pandas as pd \n",
    "data = pd.read_csv('C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/breast-cancer-wisconsin.csv')\n",
    "X=data[data.columns[1:10]]\n",
    "y=data[[\"Class\"]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982421875"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part1. 분류(Classification)\n",
    "## n_estimator=10, 10개의 데이터셋에 SVC를 훈련시킨 10개의 모델 결과를 종합하는 것이다.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "model = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0)\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[329   4]\n",
      " [  5 174]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train=confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       333\n",
      "           1       0.98      0.97      0.97       179\n",
      "\n",
      "    accuracy                           0.98       512\n",
      "   macro avg       0.98      0.98      0.98       512\n",
      "weighted avg       0.98      0.98      0.98       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_train=classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  2  58]]\n"
     ]
    }
   ],
   "source": [
    "confusion_test=confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬:\\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       111\n",
      "           1       0.92      0.97      0.94        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_test=classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part2. 회귀(Regression)\n",
    "##\n",
    "import pandas as pd\n",
    "data2=pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/house_price.csv\", encoding=\"utf-8\")\n",
    "X=data2[data2.columns[1:5]]\n",
    "y=data2[[\"house_value\"]]\n",
    "\n",
    "## train 데이터셋과 test 데이터셋을 나눠서 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "## 정규화 방법은 minmax사용하여 훈련데이터셋과 테스트데이터셋의 특성치 X 자료들을 반환한다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6928982134381334"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "model = BaggingRegressor(base_estimator=KNeighborsRegressor(), n_estimators=10, random_state=0)\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5612676280708411"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 RMSE: 52892.27111989147\n",
      "테스트 데이터 RMSE: 63323.12131927774\n"
     ]
    }
   ],
   "source": [
    "# RMSE (Root Mean Squared Error)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련 데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트 데이터 RMSE:\", np.sqrt(MSE_test))\n",
    "## 배깅 방법은 다른 앙상블 방법에서도 나타나지만 다소 훈련데이터에 과대적합되는 경향을 보인다.\n",
    "## 기저모델의 개별 최적 하이퍼파라티러르 찾고 이를 배깅에 적재하면 더 좋은 결과를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section10 앙상블 부스팅(Boosting)\n",
    "## 부스팅은 여러 개의 약한 학습기를 순차적으로 학습시켜 예측하면서 잘 못 예측한 데이터에 가중치를 부여하여 \n",
    "## 오류를 개선해 나가며 학습하는 앙상블 모델이다. \n",
    "## 배깅이 한번에 여러 개의 데이터셋에서 학습한 결과를 종합하는 병렬식 앙상블이고 부스팅은 \n",
    "## 1->2->3으로 각각 오류를 수정하며 해결해가는 순차적인 직렬식 앙상블이다.\n",
    "import pandas as pd \n",
    "data = pd.read_csv('C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/breast-cancer-wisconsin.csv')\n",
    "X=data[data.columns[1:10]]\n",
    "y=data[[\"Class\"]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part1. 분류(Classification)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[333   0]\n",
      " [  0 179]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train=confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       333\n",
      "           1       1.00      1.00      1.00       179\n",
      "\n",
      "    accuracy                           1.00       512\n",
      "   macro avg       1.00      1.00      1.00       512\n",
      "weighted avg       1.00      1.00      1.00       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_train = classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532163742690059"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  3  57]]\n"
     ]
    }
   ],
   "source": [
    "confusion_test = confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬:\\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       111\n",
      "           1       0.92      0.95      0.93        60\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.95      0.95      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_test=classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984375"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GradientBoosting 앙상블 모델 적용\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0)\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[329   4]\n",
      " [  4 175]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train=confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "confusion_test=confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬:\\n\", confusion_test)\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4353130085971758"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part2. 회귀(Regression)\n",
    "import pandas as pd\n",
    "data2=pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/house_price.csv\", encoding=\"utf-8\")\n",
    "X=data2[data2.columns[1:5]]\n",
    "y=data2[[\"house_value\"]]\n",
    "\n",
    "## train 데이터셋과 test 데이터셋을 나눠서 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "## 정규화 방법은 minmax사용하여 훈련데이터셋과 테스트데이터셋의 특성치 X 자료들을 반환한다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43568387094087124"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 RMSE: 71722.42012035428\n",
      "테스트데이터 RMSE: 71816.41231019037\n"
     ]
    }
   ],
   "source": [
    "## RMSE(Root Mean Squared Error)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE:\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6178724780500952"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GradientBoosting 앙상블 모델 적용 \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(random_state=0)\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5974112241813845"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 RMSE: 59000.433545962376\n",
      "테스트데이터 RMSE 60658.72886338227\n"
     ]
    }
   ],
   "source": [
    "# RMSE (Root Mean Squared Error)\n",
    "\n",
    "import numpy as np \n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section11 앙상블 스태킹(Stacking)\n",
    "## 스태킹은 데이터셋이 아니라 여러 학습기에서 예측한 예측값으로 다시 학습 데이터를 만들어 일반화된 최종 모델\n",
    "## 구성하는 방법이다. 핵심적인 차이는 데이터셋이 아닌 예측값들로 예측을 한다는 아이디어다.\n",
    "import pandas as pd \n",
    "data = pd.read_csv('C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/breast-cancer-wisconsin.csv')\n",
    "X=data[data.columns[1:10]]\n",
    "y=data[[\"Class\"]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.986328125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part1. 분류(Classification)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators=[('rf', RandomForestClassifier(n_estimators=10, random_state=42)), ('svr', SVC(random_state=42))]\n",
    "model=StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[330   3]\n",
      " [  4 175]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train=confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:/n               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       333\n",
      "           1       0.98      0.98      0.98       179\n",
      "\n",
      "    accuracy                           0.99       512\n",
      "   macro avg       0.99      0.98      0.98       512\n",
      "weighted avg       0.99      0.99      0.99       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cfreport_train = classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:/n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "confusion_test=confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬:\\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       111\n",
      "           1       0.92      0.98      0.95        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.97      0.96       171\n",
      "weighted avg       0.97      0.96      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfreport_test=classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_test)\n",
    "## 스태킹 앙상블은 모델을 어떻게 쌓는가에 따라서 결과가 달라진다. 현재와 같은 모델 순서를 변경하거나 \n",
    "## 다른 알고리즘을 구성하면서 충분히 개선된 성능 결과를 얻기 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4353130085971758"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part2. 회귀(Regression)\n",
    "import pandas as pd\n",
    "data2=pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/house_price.csv\", encoding=\"utf-8\")\n",
    "X=data2[data2.columns[1:5]]\n",
    "y=data2[[\"house_value\"]]\n",
    "\n",
    "## train 데이터셋과 test 데이터셋을 나눠서 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "## 정규화 방법은 minmax사용하여 훈련데이터셋과 테스트데이터셋의 특성치 X 자료들을 반환한다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.543404932348004"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "estm = [('lr', LinearRegression()), ('knn', KNeighborsRegressor())]\n",
    "model = StackingRegressor(estimators=estm, final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "                                                                                random_state=42))\n",
    "model.fit(X_scaled_train, y_train.values.ravel())\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4781188528801523"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 RMSE: 64493.60476580374\n",
      "테스트 데이터 RMSE: 69063.45138802647\n"
     ]
    }
   ],
   "source": [
    "# RMSE(Root Mean Squared Error)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련 데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트 데이터 RMSE:\", np.sqrt(MSE_test))\n",
    "## 회귀 문제에 사용한 개별 알고리즘은 선형회귀와 KNN의 회귀인데 개별 알고리즘 보다 정확도가 더 낮게 나왔다.\n",
    "## 앙상블 모델은 각각 알고리즘을 수행한 후 좋은 결과를 보이는 알고리즘과 하이퍼파라미터로 쌓아야한다. \n",
    "## 스태킹은 좋은 앙상블 모델이다. 이를 구성하는 개별 알고리즘 최적화 및 모델 순서는 스태킹 앙상블에서 중요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 12 선형회귀모델\n",
    "## \n",
    "import pandas as pd\n",
    "data2=pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/house_price.csv\", encoding=\"utf-8\")\n",
    "X=data2[data2.columns[1:5]]\n",
    "y=data2[[\"house_value\"]]\n",
    "\n",
    "## train 데이터셋과 test 데이터셋을 나눠서 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "## 정규화 방법은 minmax사용하여 훈련데이터셋과 테스트데이터셋의 특성치 X 자료들을 반환한다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train=scaler.transform(X_train)\n",
    "X_scaled_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>income</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>households</th>\n",
       "      <th>rooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17235</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0577</td>\n",
       "      <td>0.185449</td>\n",
       "      <td>3.945455</td>\n",
       "      <td>6.372727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14220</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.171566</td>\n",
       "      <td>2.741497</td>\n",
       "      <td>6.363946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.8904</td>\n",
       "      <td>0.154485</td>\n",
       "      <td>2.969325</td>\n",
       "      <td>6.651840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15279</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.241460</td>\n",
       "      <td>3.257256</td>\n",
       "      <td>4.518470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14727</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7143</td>\n",
       "      <td>0.194977</td>\n",
       "      <td>2.679287</td>\n",
       "      <td>6.385301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  income  bedrooms  households     rooms\n",
       "17235    1.0  2.0577  0.185449    3.945455  6.372727\n",
       "14220    1.0  4.0000  0.171566    2.741497  6.363946\n",
       "3280     1.0  5.8904  0.154485    2.969325  6.651840\n",
       "15279    1.0  0.9393  0.241460    3.257256  4.518470\n",
       "14727    1.0  2.7143  0.194977    2.679287  6.385301"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## statmodel 적용 \n",
    "\n",
    "import statsmodels.api as sm \n",
    "X_train_new = sm.add_constant(X_train)\n",
    "X_test_new = sm.add_constant(X_test)\n",
    "X_train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.546\n",
      "Model:                            OLS   Adj. R-squared:                  0.545\n",
      "Method:                 Least Squares   F-statistic:                     3980.\n",
      "Date:                Sun, 27 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        14:45:15   Log-Likelihood:            -1.6570e+05\n",
      "No. Observations:               13266   AIC:                         3.314e+05\n",
      "Df Residuals:                   13261   BIC:                         3.315e+05\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -2.849e+04   8884.093     -3.206      0.001   -4.59e+04   -1.11e+04\n",
      "income      5.588e+04    500.997    111.538      0.000    5.49e+04    5.69e+04\n",
      "bedrooms    5.586e+05   2.02e+04     27.637      0.000    5.19e+05    5.98e+05\n",
      "households -2.586e+04    775.128    -33.356      0.000   -2.74e+04   -2.43e+04\n",
      "rooms      -5810.6069    834.780     -6.961      0.000   -7446.896   -4174.318\n",
      "==============================================================================\n",
      "Omnibus:                     1975.541   Durbin-Watson:                   2.016\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4568.878\n",
      "Skew:                           0.866   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.294   Cond. No.                         284.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "multi_model = sm.OLS(y_train, X_train_new).fit()\n",
    "print(multi_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            house_value   R-squared:                       0.563\n",
      "Model:                            OLS   Adj. R-squared:                  0.562\n",
      "Method:                 Least Squares   F-statistic:                     1421.\n",
      "Date:                Sun, 27 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        14:47:33   Log-Likelihood:                -55169.\n",
      "No. Observations:                4423   AIC:                         1.103e+05\n",
      "Df Residuals:                    4418   BIC:                         1.104e+05\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -2.196e+04   1.48e+04     -1.483      0.138    -5.1e+04    7075.709\n",
      "income       5.57e+04    838.452     66.426      0.000    5.41e+04    5.73e+04\n",
      "bedrooms    5.402e+05   3.44e+04     15.713      0.000    4.73e+05    6.08e+05\n",
      "households -2.603e+04   1270.717    -20.484      0.000   -2.85e+04   -2.35e+04\n",
      "rooms      -6039.8888   1344.918     -4.491      0.000   -8676.601   -3403.177\n",
      "==============================================================================\n",
      "Omnibus:                      688.606   Durbin-Watson:                   1.968\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1499.714\n",
      "Skew:                           0.915   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.188   Cond. No.                         284.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "multi_model2 = sm.OLS(y_test, X_test_new).fit()\n",
    "print(multi_model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5455724996358273"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sckit-learn 적용 \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model=LinearRegression()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.562684388358716"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 RMSE: 64340.33927728243\n",
      "테스트데이터 RMSE: 63220.79672157402\n"
     ]
    }
   ],
   "source": [
    "## RMSE (Root Mean Squared Error)\n",
    "## 실제 집단과 예측된 집값 간에 평균적인 오차는 약 6.3~6.4만 달러 수준임을 의미\n",
    "import numpy as np \n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train=mean_squared_error(y_train, pred_train)\n",
    "MSE_test=mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE:\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47230.874701637375"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 기타 선형 모델평가지표: MAE(Mean Absolute Error)\n",
    "## 실제값과 예측값 차이에 절대값을 씌어 평균을 낸 오차이다.\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3996869138.1105847"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 기타 선형 모델평가지표: MSE(Mean Squared Error)\n",
    "## 실제값과 예측값의 차이, 즉 오차에 제곱을 한 오차 지표이다.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "house_value    30.571439\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 기타 섢여 모델평가지표: MAPE(Mean Absolute Percentage Error)\n",
    "## 평균 절대 오차비율은 실제값 대비 오차 정도를 백분율로 나타낸 지표이다. 일반적 선형회귀모델보다 \n",
    "## 시계열 데이터에서 주로 사용 \n",
    "\n",
    "def MAPE(y_test, pred_test):\n",
    "    return np.mean(np.abs((y_test - pred_test) / y_test)) * 100 \n",
    "MAPE(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "house_value   -12.37266\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 기타 선형 모델 평가지표: MPE(Mean Percentage Error)\n",
    "def MAE(y_test, y_pred):\n",
    "    return np.mean((y_test - y_pred) / y_test) * 100\n",
    "MAE(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5455487773718164"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Section13 릿지 회귀모델 \n",
    "## 릿지 회귀모델은 선형회귀분석의 기본 원리를 따르나 가중치(회귀계수) 값을 최대한 작게 만들어, 즉 0에 가깝게\n",
    "## 만들어 모든 독립변수(특성)가 종속변수(레비블)에 미치는 영향을 최소화하는 제약(regularization)을 반영한 회귀모델\n",
    "## 각 특성의 영향을 최소화하여 훈련데이터에 과대적합되지 않도록 제약한 모델이라고 할 수 있다.\n",
    "## 알파의 기본값은 1이며 0에 가까울수록 규제 하지 않고 커질수록 더 많은 규제한다. 하이퍼파라미터이다.\n",
    "from sklearn.linear_model import Ridge\n",
    "model=Ridge()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5626954941458684"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 RMSE 64342.018619526265\n",
      "테스트 데이터 RMSE 63219.99395904853\n"
     ]
    }
   ],
   "source": [
    "## RMSE(Root Mean Squared Error)\n",
    "\n",
    "import numpy as np \n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train=mean_squared_error(y_train, pred_train)\n",
    "MSE_test=mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련 데이터 RMSE\", np.sqrt(MSE_train))\n",
    "print(\"테스트 데이터 RMSE\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0,\n",
       "                                   10.0]})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "## alpha 값 0.0001~10등 11가지로 설정하여 그리드 탐색 해보자\n",
    "param_grid={'alpha':[1e-4, 1e-3, 1e-2, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(Ridge(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'alpha': 0.1}\n",
      "Best Score:0.5452\n",
      "TestSet Score:0.5627\n"
     ]
    }
   ],
   "source": [
    "## 점수를 보면 그다지 선형모델과 다르다. 그러므로 원래 선형모델로 충분한 예측이 가능한 데이터라는 의미\n",
    "print(\"Best Parameter:{}\".format(grid_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=Ridge(), n_iter=100,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EB5490AF48>})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "\n",
    "from scipy.stats import randint\n",
    "param_distribs = {'alpha':randint(low=0, high=100)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(Ridge(), param_distributions=param_distribs, n_iter=100, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'alpha': 0}\n",
      "Best Score:0.5452\n",
      "TestSet Score:0.5627\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter:{}\".format(random_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5455724679313863"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Section14 라쏘 회귀모델 \n",
    "## 라쏘 회귀모델은 릿지회귀모델과 유사하게 특성의 계수값을 0에 가깝게 하지만 실제 중요하지 않은 변수의 계수를\n",
    "## 0으로 만들어 불필요한 변수를 제거하는 모델이다.\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "model=Lasso()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5626850497564577"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 RMSE 64340.34152172676\n",
      "테스트데이터 RMSE 63220.748913873045\n"
     ]
    }
   ],
   "source": [
    "## RMSE (Root Mean Squared Estimator)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련데이터 RMSE\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={'alpha': [0.0, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                                   0.5, 1.0, 2.0, 3.0]})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search \n",
    "param_grid={'alpha':[0.0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 0.5, 1.0, 2.0, 3.0]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(Lasso(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'alpha': 0.5}\n",
      "Best Score:0.5452\n",
      "TestSet Score:0.5627\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter:{}\".format(grid_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=Lasso(), n_iter=100,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EB52E307C8>})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "from scipy.stats import randint\n",
    "param_distribs = {'alpha': randint(low=0.00001, high=10)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search=RandomizedSearchCV(Lasso(), param_distributions=param_distribs, n_iter=100, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'alpha': 1}\n",
      "Best Score:0.5452\n",
      "TestSet Score:0.5627\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter:{}\".format(random_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050029698219161034"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 엘라스틱넷 \n",
    "## 릿지회귀와 라쏘회귀를 절충한 모델\n",
    "## 정규화한 훈련데이터를 학습(fit)하고 예측값을 도출 및 저장(predict)한후, 정확도, 즉 설명력(score)을 구한다. 약 5%\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model=ElasticNet()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train=model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051683303919568435"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 RMSE: 93026.36648194955\n",
      "테스트데이터 RMSE: 93097.74727682666\n"
     ]
    }
   ],
   "source": [
    "# RMSE(Root Mean Squared Error)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_train=mean_squared_error(y_train, pred_train)\n",
    "MSE_test=mean_squared_error(y_test, pred_test)\n",
    "print(\"훈련데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE:\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.0, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                                   2.0, 3.0]})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid Search\n",
    "param_grid={'alpha':[0.0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 2.0, 3.0]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search=GridSearchCV(ElasticNet(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'alpha': 1e-05}\n",
      "Best Score:0.5452\n",
      "TestSet Score:0.5627\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter:{}\".format(grid_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(grid_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+13, tolerance: 9.665e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+13, tolerance: 9.671e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+13, tolerance: 9.627e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+13, tolerance: 9.648e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+13, tolerance: 9.728e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\MJ\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.746e+13, tolerance: 1.208e+10 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=ElasticNet(), n_iter=100,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EB52DBBF08>})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Search\n",
    "\n",
    "from scipy.stats import randint\n",
    "param_distribs = {'alpha':randint(low=0.00001, high=10)}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(ElasticNet(), param_distributions=param_distribs, n_iter=100, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:{'alpha': 0}\n",
      "Best Score:0.5452\n",
      "TestSet Score:0.5627\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter:{}\".format(random_search.best_params_))\n",
    "print(\"Best Score:{:.4f}\".format(random_search.best_score_))\n",
    "print(\"TestSet Score:{:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 군집분석 \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-deep')\n",
    "import matplotlib.cm\n",
    "cmap=matplotlib.cm.get_cmap('plasma')\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  Spend\n",
       "0      15     39\n",
       "1      15     81\n",
       "2      16      6\n",
       "3      16     77\n",
       "4      17     40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/Mall_Customers.csv\", \n",
    "                   encoding=\"UTF-8-sig\")\n",
    "X = data.iloc[:, [3,4]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Gender  Age  Income  Spend\n",
       "0   1    Male   19      15     39\n",
       "1   2    Male   21      15     81\n",
       "2   3  Female   20      16      6\n",
       "3   4  Female   23      16     77\n",
       "4   5  Female   31      17     40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[269981.28,\n",
       " 181363.59595959593,\n",
       " 106348.37306211118,\n",
       " 73679.78903948836,\n",
       " 44448.45544793371,\n",
       " 37233.81451071001,\n",
       " 30241.343617936593,\n",
       " 25094.432930794697,\n",
       " 21850.165282585633,\n",
       " 19643.655552199743,\n",
       " 17615.645251508537,\n",
       " 15817.245013841313,\n",
       " 15039.833115095615,\n",
       " 12793.951692914929,\n",
       " 11938.461998527788,\n",
       " 10803.381903622692,\n",
       " 10295.765823307127,\n",
       " 9792.53878066378,\n",
       " 8774.008935097298,\n",
       " 8152.179531167894]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcss = []\n",
    "\n",
    "for i in range(1, 21):\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit_transform(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "wcss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['Hancom Gothic Regular'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['Hancom Gothic Regular'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1,21), wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2,\n",
       "       4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 1,\n",
       "       4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 0, 1, 0, 3, 0, 3, 0,\n",
       "       1, 0, 3, 0, 3, 0, 3, 0, 3, 0, 1, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0,\n",
       "       3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0,\n",
       "       3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0,\n",
       "       3, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=5\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Spend</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>120</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>126</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>126</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>137</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>137</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Gender  Age  Income  Spend  Group\n",
       "0      1    Male   19      15     39      4\n",
       "1      2    Male   21      15     81      2\n",
       "2      3  Female   20      16      6      4\n",
       "3      4  Female   23      16     77      2\n",
       "4      5  Female   31      17     40      4\n",
       "..   ...     ...  ...     ...    ...    ...\n",
       "195  196  Female   35     120     79      0\n",
       "196  197  Female   45     126     28      3\n",
       "197  198    Male   32     126     74      0\n",
       "198  199    Male   32     137     18      3\n",
       "199  200    Male   30     137     83      0\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Group_cluster=pd.DataFrame(y_kmeans)\n",
    "Group_cluster.columns=['Group']\n",
    "full_data=pd.concat([data, Group_cluster], axis=1)\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55.2962963 , 49.51851852],\n",
       "       [88.2       , 17.11428571],\n",
       "       [26.30434783, 20.91304348],\n",
       "       [25.72727273, 79.36363636],\n",
       "       [86.53846154, 82.12820513]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_pred=KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "kmeans_pred.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_pred.predict([[100, 50], [30, 80]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4', 'Cluster5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [('Cluster' + str(i+1)) for i in range(k)]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X=np.array(X)\n",
    "plt.figure()\n",
    "for i in range(k):\n",
    "    plt.scatter(X[y_kmeans == i, 0], X[y_kmeans == i, 1], s=20, c = cmap(i/k), label=labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],\n",
    "           s=100, c='black', label='Centroids', marker='X')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Spend')\n",
    "plt.title('Kmeans cluster plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(k):\n",
    "    plt.scatter(X[y_kmeans==i,0], X[y_kmeans==i, 1], s=20, c=cmap(i/k), label=labels[i])\n",
    "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=100, \n",
    "            c='black', label='Centroids', marker='X')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Spend')\n",
    "plt.title('Kmeans cluster plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-mean Clustering\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "iris = pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/iris.csv\", encoding=\"UTF-8-sig\")\n",
    "print(iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_iris = iris.drop(['class'], axis=1)\n",
    "y_iris = iris[\"class\"]\n",
    "X_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Iris-setosa\n",
       "1    Iris-setosa\n",
       "2    Iris-setosa\n",
       "3    Iris-setosa\n",
       "4    Iris-setosa\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.032057</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.143017</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.385353</td>\n",
       "      <td>0.337848</td>\n",
       "      <td>-1.398138</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.506521</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>-1.284407</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.021849</td>\n",
       "      <td>1.263460</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0 -0.900681  1.032057 -1.341272 -1.312977\n",
       "1 -1.143017 -0.124958 -1.341272 -1.312977\n",
       "2 -1.385353  0.337848 -1.398138 -1.312977\n",
       "3 -1.506521  0.106445 -1.284407 -1.312977\n",
       "4 -1.021849  1.263460 -1.341272 -1.312977"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale=StandardScaler()\n",
    "scale.fit(X_iris)\n",
    "X_scale=scale.transform(X_iris)\n",
    "pd.DataFrame(X_scale).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = range(1,10)\n",
    "KM = [KMeans(n_clusters=k).fit(X_scale) for k in K]\n",
    "centroids = [k.cluster_centers_ for k in KM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6.34507683],\n",
       "        [ 5.91692488],\n",
       "        [ 5.83609458],\n",
       "        [ 5.7497826 ],\n",
       "        [ 6.32139225],\n",
       "        [ 6.88621812],\n",
       "        [ 5.8966092 ],\n",
       "        [ 6.23297682],\n",
       "        [ 5.45618915],\n",
       "        [ 5.98999165],\n",
       "        [ 6.71863081],\n",
       "        [ 6.09918027],\n",
       "        [ 5.83180932],\n",
       "        [ 5.35817133],\n",
       "        [ 7.14982517],\n",
       "        [ 7.36613874],\n",
       "        [ 6.79852925],\n",
       "        [ 6.34901567],\n",
       "        [ 7.06470098],\n",
       "        [ 6.54140658],\n",
       "        [ 6.60681466],\n",
       "        [ 6.48922183],\n",
       "        [ 5.92958683],\n",
       "        [ 6.32771681],\n",
       "        [ 6.18465844],\n",
       "        [ 6.04979338],\n",
       "        [ 6.26737585],\n",
       "        [ 6.44825558],\n",
       "        [ 6.37181293],\n",
       "        [ 5.91016074],\n",
       "        [ 5.93717104],\n",
       "        [ 6.56734345],\n",
       "        [ 6.79043445],\n",
       "        [ 7.06328535],\n",
       "        [ 5.98999165],\n",
       "        [ 6.05970296],\n",
       "        [ 6.65056389],\n",
       "        [ 5.98999165],\n",
       "        [ 5.48543526],\n",
       "        [ 6.31347765],\n",
       "        [ 6.24739946],\n",
       "        [ 5.22685374],\n",
       "        [ 5.59732079],\n",
       "        [ 6.33798075],\n",
       "        [ 6.64981203],\n",
       "        [ 5.83866423],\n",
       "        [ 6.56124988],\n",
       "        [ 5.77927331],\n",
       "        [ 6.63852393],\n",
       "        [ 6.15548536],\n",
       "        [ 9.12633552],\n",
       "        [ 8.58487041],\n",
       "        [ 9.13673902],\n",
       "        [ 7.29588925],\n",
       "        [ 8.5732141 ],\n",
       "        [ 7.89113427],\n",
       "        [ 8.67352293],\n",
       "        [ 6.45445583],\n",
       "        [ 8.64985549],\n",
       "        [ 7.17635005],\n",
       "        [ 6.5       ],\n",
       "        [ 7.98122798],\n",
       "        [ 7.60526134],\n",
       "        [ 8.3468557 ],\n",
       "        [ 7.37699126],\n",
       "        [ 8.70746806],\n",
       "        [ 7.92842986],\n",
       "        [ 7.6642025 ],\n",
       "        [ 8.11048704],\n",
       "        [ 7.35051019],\n",
       "        [ 8.44570897],\n",
       "        [ 7.92085854],\n",
       "        [ 8.49705831],\n",
       "        [ 8.28130425],\n",
       "        [ 8.33966426],\n",
       "        [ 8.59534758],\n",
       "        [ 8.89269363],\n",
       "        [ 9.04322951],\n",
       "        [ 8.1798533 ],\n",
       "        [ 7.24568837],\n",
       "        [ 7.18748913],\n",
       "        [ 7.12039325],\n",
       "        [ 7.58814865],\n",
       "        [ 8.47702778],\n",
       "        [ 7.78845299],\n",
       "        [ 8.38868285],\n",
       "        [ 8.87918915],\n",
       "        [ 8.12588457],\n",
       "        [ 7.67202711],\n",
       "        [ 7.36138574],\n",
       "        [ 7.60328876],\n",
       "        [ 8.32646384],\n",
       "        [ 7.60526134],\n",
       "        [ 6.49461315],\n",
       "        [ 7.61445993],\n",
       "        [ 7.78267306],\n",
       "        [ 7.76079893],\n",
       "        [ 8.18718511],\n",
       "        [ 6.5169011 ],\n",
       "        [ 7.67007171],\n",
       "        [ 9.63483264],\n",
       "        [ 8.39940474],\n",
       "        [ 9.93126377],\n",
       "        [ 9.09395404],\n",
       "        [ 9.47259204],\n",
       "        [10.71120908],\n",
       "        [ 7.30753036],\n",
       "        [10.22888068],\n",
       "        [ 9.38189746],\n",
       "        [10.40480658],\n",
       "        [ 9.08295106],\n",
       "        [ 8.94147639],\n",
       "        [ 9.48156105],\n",
       "        [ 8.23043134],\n",
       "        [ 8.55862138],\n",
       "        [ 9.19673855],\n",
       "        [ 9.20543318],\n",
       "        [11.11125555],\n",
       "        [10.90642013],\n",
       "        [ 8.2516665 ],\n",
       "        [ 9.77905926],\n",
       "        [ 8.19817053],\n",
       "        [10.77125805],\n",
       "        [ 8.61568337],\n",
       "        [ 9.62704524],\n",
       "        [10.06578363],\n",
       "        [ 8.51821578],\n",
       "        [ 8.57088093],\n",
       "        [ 9.19619487],\n",
       "        [ 9.85088828],\n",
       "        [10.16956243],\n",
       "        [11.03675677],\n",
       "        [ 9.21954446],\n",
       "        [ 8.70574523],\n",
       "        [ 8.79147314],\n",
       "        [10.52568288],\n",
       "        [ 9.4005319 ],\n",
       "        [ 9.16842407],\n",
       "        [ 8.44274837],\n",
       "        [ 9.52837867],\n",
       "        [ 9.57183368],\n",
       "        [ 9.40850679],\n",
       "        [ 8.39940474],\n",
       "        [ 9.8275124 ],\n",
       "        [ 9.72213968],\n",
       "        [ 9.28547252],\n",
       "        [ 8.63423419],\n",
       "        [ 9.07138358],\n",
       "        [ 9.18966811],\n",
       "        [ 8.54751426]]),\n",
       " array([[ 6.10000756,  7.34065224],\n",
       "        [ 5.63399101,  7.00511603],\n",
       "        [ 5.59407898,  6.86424946],\n",
       "        [ 5.4817854 ,  6.82681606],\n",
       "        [ 6.09063058,  7.29477883],\n",
       "        [ 6.61514566,  7.89082098],\n",
       "        [ 5.65841305,  6.91376044],\n",
       "        [ 5.97384563,  7.25959342],\n",
       "        [ 5.18892219,  6.55633533],\n",
       "        [ 5.71761404,  7.05571677],\n",
       "        [ 6.46712394,  7.70051788],\n",
       "        [ 5.84031331,  7.13490299],\n",
       "        [ 5.5649641 ,  6.9005586 ],\n",
       "        [ 5.15437469,  6.36554814],\n",
       "        [ 6.93123481,  8.04992719],\n",
       "        [ 7.13988147,  8.26737836],\n",
       "        [ 6.56369586,  7.747332  ],\n",
       "        [ 6.09381485,  7.3611277 ],\n",
       "        [ 6.78137601,  8.07968061],\n",
       "        [ 6.30371189,  7.51144411],\n",
       "        [ 6.31031096,  7.67041792],\n",
       "        [ 6.23273937,  7.49408298],\n",
       "        [ 5.76398853,  6.82335932],\n",
       "        [ 6.0044674 ,  7.45238903],\n",
       "        [ 5.89642231,  7.26221507],\n",
       "        [ 5.74190048,  7.168439  ],\n",
       "        [ 5.97790248,  7.34130259],\n",
       "        [ 6.18854963,  7.46117061],\n",
       "        [ 6.11264294,  7.388948  ],\n",
       "        [ 5.6366884 ,  6.98361279],\n",
       "        [ 5.64858987,  7.03293856],\n",
       "        [ 6.26976669,  7.63514317],\n",
       "        [ 6.59234734,  7.67706148],\n",
       "        [ 6.85739567,  7.94654699],\n",
       "        [ 5.71761404,  7.05571677],\n",
       "        [ 5.81204214,  7.07995002],\n",
       "        [ 6.39568202,  7.64237286],\n",
       "        [ 5.71761404,  7.05571677],\n",
       "        [ 5.24019389,  6.54798411],\n",
       "        [ 6.04941102,  7.34265704],\n",
       "        [ 6.0072061 ,  7.24170626],\n",
       "        [ 4.88600516,  6.46059339],\n",
       "        [ 5.37290362,  6.6165832 ],\n",
       "        [ 6.03808935,  7.42417092],\n",
       "        [ 6.36547873,  7.69069055],\n",
       "        [ 5.54957653,  6.94260473],\n",
       "        [ 6.3239077 ,  7.52939192],\n",
       "        [ 5.53215055,  6.82026249],\n",
       "        [ 6.39180334,  7.61741819],\n",
       "        [ 5.8968711 ,  7.18673655],\n",
       "        [ 8.49984984, 10.62546306],\n",
       "        [ 7.96251577, 10.09069101],\n",
       "        [ 8.48929832, 10.66906687],\n",
       "        [ 6.63250837,  8.9014058 ],\n",
       "        [ 7.91408801, 10.13704996],\n",
       "        [ 7.25230762,  9.44157976],\n",
       "        [ 8.04554893, 10.18595331],\n",
       "        [ 5.86541549,  7.98117549],\n",
       "        [ 8.01165323, 10.17900707],\n",
       "        [ 6.55030066,  8.72997609],\n",
       "        [ 5.85608594,  8.10480566],\n",
       "        [ 7.35744175,  9.50586459],\n",
       "        [ 6.95594607,  9.18014098],\n",
       "        [ 7.6998621 ,  9.89745459],\n",
       "        [ 6.79014321,  8.86415649],\n",
       "        [ 8.08634984, 10.20819535],\n",
       "        [ 7.29416611,  9.47077829],\n",
       "        [ 7.05540694,  9.1753924 ],\n",
       "        [ 7.40555646,  9.75606616],\n",
       "        [ 6.72597088,  8.89595364],\n",
       "        [ 7.79557213,  9.99867342],\n",
       "        [ 7.30154596,  9.44035027],\n",
       "        [ 7.80330374, 10.11643521],\n",
       "        [ 7.63967744,  9.82527441],\n",
       "        [ 7.71433515,  9.85664376],\n",
       "        [ 7.96657273, 10.11102358],\n",
       "        [ 8.23243296, 10.45081121],\n",
       "        [ 8.37289421, 10.61388924],\n",
       "        [ 7.53424163,  9.73271626],\n",
       "        [ 6.65874773,  8.73770663],\n",
       "        [ 6.55868885,  8.74485912],\n",
       "        [ 6.50479824,  8.66028635],\n",
       "        [ 6.97342936,  9.11086855],\n",
       "        [ 7.78703382, 10.09106379],\n",
       "        [ 7.15596081,  9.33219212],\n",
       "        [ 7.77948826,  9.87899209],\n",
       "        [ 8.23966489, 10.40486449],\n",
       "        [ 7.44691566,  9.73150832],\n",
       "        [ 7.06950043,  9.17331386],\n",
       "        [ 6.71704017,  8.93633608],\n",
       "        [ 6.95890946,  9.17074251],\n",
       "        [ 7.69172249,  9.85850751],\n",
       "        [ 6.97667532,  9.14862628],\n",
       "        [ 5.89384512,  8.03682396],\n",
       "        [ 6.97958856,  9.1671177 ],\n",
       "        [ 7.18201946,  9.27752946],\n",
       "        [ 7.14364472,  9.28181232],\n",
       "        [ 7.56266372,  9.70708992],\n",
       "        [ 5.94645813,  8.01340322],\n",
       "        [ 7.04825632,  9.20106112],\n",
       "        [ 8.91655202, 11.26967436],\n",
       "        [ 7.69118151, 10.04324718],\n",
       "        [ 9.2126589 , 11.56153934],\n",
       "        [ 8.39276585, 10.71206436],\n",
       "        [ 8.75138882, 11.11493352],\n",
       "        [ 9.97759388, 12.35356631],\n",
       "        [ 6.61686372,  8.95318876],\n",
       "        [ 9.51002233, 11.8547168 ],\n",
       "        [ 8.64608516, 11.04879101],\n",
       "        [ 9.70278223, 12.00072472],\n",
       "        [ 8.40771718, 10.66048514],\n",
       "        [ 8.22706205, 10.583301  ],\n",
       "        [ 8.77322113, 11.1034473 ],\n",
       "        [ 7.50214933,  9.90862608],\n",
       "        [ 7.83013023, 10.23002841],\n",
       "        [ 8.49903829, 10.80731494],\n",
       "        [ 8.51412481, 10.80577241],\n",
       "        [10.42107319, 12.67705908],\n",
       "        [10.13368195, 12.60921648],\n",
       "        [ 7.53012238,  9.91916699],\n",
       "        [ 9.06942176, 11.39765492],\n",
       "        [ 7.49912543,  9.83267997],\n",
       "        [10.02833413, 12.42780709],\n",
       "        [ 7.9191838 , 10.23662131],\n",
       "        [ 8.93546771, 11.21963428],\n",
       "        [ 9.37422734, 11.65045422],\n",
       "        [ 7.83323997, 10.12354004],\n",
       "        [ 7.89930882, 10.15417156],\n",
       "        [ 8.47031826, 10.85093439],\n",
       "        [ 9.16185998, 11.43529639],\n",
       "        [ 9.44353212, 11.8078263 ],\n",
       "        [10.36283455, 12.57691059],\n",
       "        [ 8.488273  , 10.88227011],\n",
       "        [ 8.02952462, 10.29314474],\n",
       "        [ 8.09202038, 10.41315382],\n",
       "        [ 9.79348432, 12.16843004],\n",
       "        [ 8.70497529, 11.00373438],\n",
       "        [ 8.48504625, 10.75701354],\n",
       "        [ 7.77502576, 10.02313866],\n",
       "        [ 8.83021345, 11.13328436],\n",
       "        [ 8.85257427, 11.20933618],\n",
       "        [ 8.70879483, 11.01812802],\n",
       "        [ 7.69118151, 10.04324718],\n",
       "        [ 9.11289709, 11.45319053],\n",
       "        [ 9.01002396, 11.34567302],\n",
       "        [ 8.57503963, 10.91433693],\n",
       "        [ 7.91258554, 10.29355818],\n",
       "        [ 8.37739572, 10.67866292],\n",
       "        [ 8.50555943, 10.77897386],\n",
       "        [ 7.87026175, 10.14018343]]),\n",
       " array([[ 6.84296318,  7.34065224,  5.30353099],\n",
       "        [ 6.37775551,  7.00511603,  4.84029208],\n",
       "        [ 6.33461131,  6.86424946,  4.80556244],\n",
       "        [ 6.22914003,  6.82681606,  4.68416863],\n",
       "        [ 6.83316614,  7.29477883,  5.29483855],\n",
       "        [ 7.37557904,  7.89082098,  5.78998693],\n",
       "        [ 6.40729695,  6.91376044,  4.85688136],\n",
       "        [ 6.72015896,  7.25959342,  5.17346117],\n",
       "        [ 5.93375826,  6.55633533,  4.39814932],\n",
       "        [ 6.45822964,  7.05571677,  4.92780762],\n",
       "        [ 7.21241204,  7.70051788,  5.66462401],\n",
       "        [ 6.58945689,  7.13490299,  5.03684766],\n",
       "        [ 6.3025498 ,  6.9005586 ,  4.7811145 ],\n",
       "        [ 5.880513  ,  6.36554814,  4.39235572],\n",
       "        [ 7.66653491,  8.04992719,  6.13995053],\n",
       "        [ 7.89231288,  8.26737836,  6.32331215],\n",
       "        [ 7.3128101 ,  7.747332  ,  5.75508171],\n",
       "        [ 6.84249461,  7.3611277 ,  5.2890459 ],\n",
       "        [ 7.53655441,  8.07968061,  5.96281147],\n",
       "        [ 7.05396351,  7.51144411,  5.4951609 ],\n",
       "        [ 7.06128173,  7.67041792,  5.50067413],\n",
       "        [ 6.98898635,  7.49408298,  5.41596516],\n",
       "        [ 6.49076336,  6.82335932,  4.99410736],\n",
       "        [ 6.77320245,  7.45238903,  5.17088141],\n",
       "        [ 6.65300106,  7.26221507,  5.08154226],\n",
       "        [ 6.49128621,  7.168439  ,  4.93889917],\n",
       "        [ 6.73856103,  7.34130259,  5.1564113 ],\n",
       "        [ 6.9344562 ,  7.46117061,  5.38711358],\n",
       "        [ 6.85566414,  7.388948  ,  5.31597278],\n",
       "        [ 6.38660954,  6.98361279,  4.83380469],\n",
       "        [ 6.39865354,  7.03293856,  4.84538888],\n",
       "        [ 7.02622851,  7.63514317,  5.45243574],\n",
       "        [ 7.33003722,  7.67706148,  5.79987146],\n",
       "        [ 7.59794246,  7.94654699,  6.05916058],\n",
       "        [ 6.45822964,  7.05571677,  4.92780762],\n",
       "        [ 6.54881201,  7.07995002,  5.02703714],\n",
       "        [ 7.13483198,  7.64237286,  5.60249221],\n",
       "        [ 6.45822964,  7.05571677,  4.92780762],\n",
       "        [ 5.98122494,  6.54798411,  4.45462141],\n",
       "        [ 6.79562951,  7.34265704,  5.24857185],\n",
       "        [ 6.75271759,  7.24170626,  5.20773029],\n",
       "        [ 5.63260815,  6.46059339,  4.0961276 ],\n",
       "        [ 6.11286909,  6.6165832 ,  4.58748434],\n",
       "        [ 6.8089234 ,  7.42417092,  5.20119112],\n",
       "        [ 7.13119648,  7.69069055,  5.53410717],\n",
       "        [ 6.29994514,  6.94260473,  4.7468081 ],\n",
       "        [ 7.0714431 ,  7.52939192,  5.51914608],\n",
       "        [ 6.27596607,  6.82026249,  4.73934281],\n",
       "        [ 7.13714533,  7.61741819,  5.58973696],\n",
       "        [ 6.64033014,  7.18673655,  5.10130124],\n",
       "        [ 9.30312552, 10.62546306,  7.60802943],\n",
       "        [ 8.7738521 , 10.09069101,  7.06047804],\n",
       "        [ 9.29282609, 10.66906687,  7.59714965],\n",
       "        [ 7.43612242,  8.9014058 ,  5.74474661],\n",
       "        [ 8.71876051, 10.13704996,  7.02147995],\n",
       "        [ 8.05535627,  9.44157976,  6.36355687],\n",
       "        [ 8.85895421, 10.18595331,  7.1404679 ],\n",
       "        [ 6.67064416,  7.98117549,  4.97805592],\n",
       "        [ 8.81111301, 10.17900707,  7.12611645],\n",
       "        [ 7.36567117,  8.72997609,  5.64555018],\n",
       "        [ 6.6523899 ,  8.10480566,  4.98223013],\n",
       "        [ 8.17231076,  9.50586459,  6.45156744],\n",
       "        [ 7.74269437,  9.18014098,  6.09145025],\n",
       "        [ 8.50350361,  9.89745459,  6.80917157],\n",
       "        [ 7.60462597,  8.86415649,  5.88608684],\n",
       "        [ 8.89272024, 10.20819535,  7.19102053],\n",
       "        [ 8.10604787,  9.47077829,  6.39269443],\n",
       "        [ 7.85111544,  9.1753924 ,  6.17772625],\n",
       "        [ 8.20242702,  9.75606616,  6.52517702],\n",
       "        [ 7.52598226,  8.89595364,  5.8431501 ],\n",
       "        [ 8.61292655,  9.99867342,  6.88536526],\n",
       "        [ 8.10841984,  9.44035027,  6.40721085],\n",
       "        [ 8.60000016, 10.11643521,  6.92212144],\n",
       "        [ 8.43542178,  9.82527441,  6.76025191],\n",
       "        [ 8.51787201,  9.85664376,  6.82375897],\n",
       "        [ 8.77236404, 10.11102358,  7.0722903 ],\n",
       "        [ 9.03018919, 10.45081121,  7.34877708],\n",
       "        [ 9.18031257, 10.61388924,  7.47557808],\n",
       "        [ 8.34398764,  9.73271626,  6.63529091],\n",
       "        [ 7.45861578,  8.73770663,  5.7763605 ],\n",
       "        [ 7.35892743,  8.74485912,  5.67610527],\n",
       "        [ 7.30203615,  8.66028635,  5.62679835],\n",
       "        [ 7.7785732 ,  9.11086855,  6.0824289 ],\n",
       "        [ 8.58758186, 10.09106379,  6.90049022],\n",
       "        [ 7.96793098,  9.33219212,  6.25467266],\n",
       "        [ 8.5968604 ,  9.87899209,  6.86928327],\n",
       "        [ 9.04629988, 10.40486449,  7.34367615],\n",
       "        [ 8.24003902,  9.73150832,  6.57172309],\n",
       "        [ 7.88028317,  9.17331386,  6.17012379],\n",
       "        [ 7.52383103,  8.93633608,  5.82438617],\n",
       "        [ 7.75773672,  9.17074251,  6.07705292],\n",
       "        [ 8.49794907,  9.85850751,  6.79740774],\n",
       "        [ 7.77950103,  9.14862628,  6.08900704],\n",
       "        [ 6.69712469,  8.03682396,  5.00930798],\n",
       "        [ 7.78596053,  9.1671177 ,  6.08679985],\n",
       "        [ 7.9878541 ,  9.27752946,  6.28946847],\n",
       "        [ 7.95193952,  9.28181232,  6.24766348],\n",
       "        [ 8.36744021,  9.70708992,  6.67068771],\n",
       "        [ 6.75690359,  8.01340322,  5.05090697],\n",
       "        [ 7.85663987,  9.20106112,  6.15238758],\n",
       "        [ 9.72983933, 11.26967436,  8.0103101 ],\n",
       "        [ 8.49983743, 10.04324718,  6.79344171],\n",
       "        [10.0158428 , 11.56153934,  8.31976359],\n",
       "        [ 9.19284797, 10.71206436,  7.50555821],\n",
       "        [ 9.55876231, 11.11493352,  7.85349924],\n",
       "        [10.76943743, 12.35356631,  9.09877555],\n",
       "        [ 7.42863293,  8.95318876,  5.71722223],\n",
       "        [10.29817213, 11.8547168 ,  8.63693719],\n",
       "        [ 9.43532637, 11.04879101,  7.77324888],\n",
       "        [10.51897514, 12.00072472,  8.79164991],\n",
       "        [ 9.22450125, 10.66048514,  7.49736348],\n",
       "        [ 9.03152742, 10.583301  ,  7.33411055],\n",
       "        [ 9.58305799, 11.1034473 ,  7.87191623],\n",
       "        [ 8.31192934,  9.90862608,  6.60321918],\n",
       "        [ 8.65108267, 10.23002841,  6.91479275],\n",
       "        [ 9.3195026 , 10.80731494,  7.58345842],\n",
       "        [ 9.31740879, 10.80577241,  7.62226675],\n",
       "        [11.22512247, 12.67705908,  9.52540164],\n",
       "        [10.91719968, 12.60921648,  9.26569856],\n",
       "        [ 8.31998735,  9.91916699,  6.65928317],\n",
       "        [ 9.88308268, 11.39765492,  8.16246621],\n",
       "        [ 8.31539577,  9.83267997,  6.59097813],\n",
       "        [10.81275248, 12.42780709,  9.15933087],\n",
       "        [ 8.72770769, 10.23662131,  7.02116962],\n",
       "        [ 9.74649265, 11.21963428,  8.03229679],\n",
       "        [10.17197126, 11.65045422,  8.48844401],\n",
       "        [ 8.64513749, 10.12354004,  6.93065302],\n",
       "        [ 8.71269009, 10.15417156,  6.99451584],\n",
       "        [ 9.27594747, 10.85093439,  7.57530372],\n",
       "        [ 9.95433175, 11.43529639,  8.28358003],\n",
       "        [10.23518124, 11.8078263 ,  8.56585569],\n",
       "        [11.16668289, 12.57691059,  9.46749807],\n",
       "        [ 9.29606309, 10.88227011,  7.59024322],\n",
       "        [ 8.8283161 , 10.29314474,  7.14487913],\n",
       "        [ 8.87557556, 10.41315382,  7.22838078],\n",
       "        [10.59648682, 12.16843004,  8.89999577],\n",
       "        [ 9.52471888, 11.00373438,  7.79013474],\n",
       "        [ 9.28978584, 10.75701354,  7.59123342],\n",
       "        [ 8.59013568, 10.02313866,  6.8680201 ],\n",
       "        [ 9.64264534, 11.13328436,  7.92526375],\n",
       "        [ 9.66862299, 11.20933618,  7.94263068],\n",
       "        [ 9.52923412, 11.01812802,  7.7929904 ],\n",
       "        [ 8.49983743, 10.04324718,  6.79344171],\n",
       "        [ 9.92352088, 11.45319053,  8.21002681],\n",
       "        [ 9.82896069, 11.34567302,  8.09592825],\n",
       "        [ 9.39364946, 10.91433693,  7.66192881],\n",
       "        [ 8.71864931, 10.29355818,  7.01803203],\n",
       "        [ 9.19020132, 10.67866292,  7.47260626],\n",
       "        [ 9.32660984, 10.77897386,  7.58915912],\n",
       "        [ 8.68054538, 10.14018343,  6.96987314]]),\n",
       " array([[ 6.85911304,  5.31103072,  6.863833  ,  7.86040792],\n",
       "        [ 6.55872604,  4.84734681,  6.39877404,  7.49596608],\n",
       "        [ 6.3969141 ,  4.81264636,  6.35546475,  7.37417282],\n",
       "        [ 6.37174494,  4.6915973 ,  6.24996716,  7.32630841],\n",
       "        [ 6.80472453,  5.30244246,  6.85394146,  7.82217451],\n",
       "        [ 7.39571174,  5.79893808,  7.39626993,  8.42001502],\n",
       "        [ 6.43344447,  4.86478503,  6.4279334 ,  7.43465216],\n",
       "        [ 6.78645633,  5.18108716,  6.74102097,  7.77241901],\n",
       "        [ 6.11277775,  4.40517973,  5.95461322,  7.04756041],\n",
       "        [ 6.60329598,  4.93477391,  6.47922564,  7.55154647],\n",
       "        [ 7.21199316,  5.6724107 ,  7.23330062,  8.22473097],\n",
       "        [ 6.66193603,  5.04471304,  6.6102068 ,  7.64822746],\n",
       "        [ 6.45228207,  4.78777646,  6.32356947,  7.39368431],\n",
       "        [ 5.90254921,  4.39835173,  5.90133226,  6.87483909],\n",
       "        [ 7.54185016,  6.14736624,  7.68745216,  8.58989204],\n",
       "        [ 7.74204733,  6.33213006,  7.9129307 ,  8.8217281 ],\n",
       "        [ 7.2426714 ,  5.76333835,  7.33354078,  8.28547589],\n",
       "        [ 6.8804101 ,  5.29691383,  6.86332415,  7.88006679],\n",
       "        [ 7.59419253,  5.97126649,  7.55744737,  8.59964016],\n",
       "        [ 7.01267691,  5.5034446 ,  7.07463327,  8.04543607],\n",
       "        [ 7.2073191 ,  5.50857033,  7.08226035,  8.1724089 ],\n",
       "        [ 7.00293315,  5.42453533,  7.00966314,  8.02150736],\n",
       "        [ 6.31622397,  5.00094052,  6.51133407,  7.36782688],\n",
       "        [ 6.9955065 ,  5.17990045,  6.79397472,  7.94998031],\n",
       "        [ 6.79791064,  5.08997446,  6.67366655,  7.76730583],\n",
       "        [ 6.7282502 ,  4.94634179,  6.5123012 ,  7.65289345],\n",
       "        [ 6.8725016 ,  5.16498452,  6.7593188 ,  7.84992119],\n",
       "        [ 6.98353989,  5.39478172,  6.95535506,  7.9769291 ],\n",
       "        [ 6.91596612,  5.32336348,  6.87661933,  7.90098799],\n",
       "        [ 6.52462317,  4.84151581,  6.40741161,  7.48559158],\n",
       "        [ 6.58284613,  4.85298122,  6.41954932,  7.52686388],\n",
       "        [ 7.16871954,  5.46068106,  7.0471588 ,  8.14023195],\n",
       "        [ 7.15906941,  5.80765245,  7.35067276,  8.22711156],\n",
       "        [ 7.42569809,  6.06711602,  7.61864631,  8.4980774 ],\n",
       "        [ 6.60329598,  4.93477391,  6.47922564,  7.55154647],\n",
       "        [ 6.61418474,  5.03386715,  6.56979645,  7.58729454],\n",
       "        [ 7.16426502,  5.60972547,  7.15585495,  8.15770347],\n",
       "        [ 6.60329598,  4.93477391,  6.47922564,  7.55154647],\n",
       "        [ 6.09304211,  4.46153254,  6.0020409 ,  7.04912216],\n",
       "        [ 6.8708312 ,  5.25617572,  6.81653336,  7.85391603],\n",
       "        [ 6.75704414,  5.2154265 ,  6.77351148,  7.76466788],\n",
       "        [ 6.0700801 ,  4.1025927 ,  5.65373849,  6.90621134],\n",
       "        [ 6.14520255,  4.5946064 ,  6.13356682,  7.13147429],\n",
       "        [ 6.95022858,  5.21057868,  6.82953101,  7.93687872],\n",
       "        [ 7.20350693,  5.54344343,  7.15174379,  8.21377036],\n",
       "        [ 6.49593464,  4.75429289,  6.3208829 ,  7.43407343],\n",
       "        [ 7.03243143,  5.52725585,  7.09213777,  8.06172978],\n",
       "        [ 6.35438777,  4.74665666,  6.29675836,  7.3291753 ],\n",
       "        [ 7.1274479 ,  5.59754626,  7.15799374,  8.14326101],\n",
       "        [ 6.71838876,  5.10863906,  6.66125312,  7.69575926],\n",
       "        [10.25561885,  7.6216012 ,  9.32247669, 11.03115163],\n",
       "        [ 9.7188583 ,  7.07466837,  8.79300925, 10.50004651],\n",
       "        [10.3096534 ,  7.6110823 ,  9.31191408, 11.06490472],\n",
       "        [ 8.58062251,  5.75841453,  7.45516359,  9.26855228],\n",
       "        [ 9.79090904,  7.03543065,  8.73781886, 10.52239314],\n",
       "        [ 9.09659036,  6.37762742,  8.07417761,  9.82863135],\n",
       "        [ 9.81355155,  7.15512661,  8.87785621, 10.59549854],\n",
       "        [ 7.63897719,  4.99084372,  6.6902117 ,  8.3730189 ],\n",
       "        [ 9.82538472,  7.13954296,  8.83036157, 10.57115312],\n",
       "        [ 8.38148778,  5.66001738,  7.38461141,  9.1235257 ],\n",
       "        [ 7.79805947,  4.99477491,  6.67176111,  8.46339836],\n",
       "        [ 9.14144396,  6.46594864,  8.19140136,  9.91060136],\n",
       "        [ 8.86124887,  6.10365621,  7.76216227,  9.54417827],\n",
       "        [ 9.54878018,  6.82331524,  8.52235181, 10.28606364],\n",
       "        [ 8.49200849,  5.89973295,  7.6241511 ,  9.27876209],\n",
       "        [ 9.83876765,  7.20460753,  8.91213872, 10.61490694],\n",
       "        [ 9.11477918,  6.40749914,  8.12470045,  9.86788613],\n",
       "        [ 8.82570192,  6.19055109,  7.87051465,  9.56795332],\n",
       "        [ 9.44773949,  6.53894625,  8.22123775, 10.10766867],\n",
       "        [ 8.55701339,  5.85617548,  7.54535272,  9.2799029 ],\n",
       "        [ 9.63756086,  6.9008546 ,  8.63135161, 10.3984352 ],\n",
       "        [ 9.08223291,  6.42063004,  8.1278787 ,  9.83954092],\n",
       "        [ 9.79591267,  6.93619881,  8.61862648, 10.47796312],\n",
       "        [ 9.48181438,  6.77381471,  8.45437029, 10.20932535],\n",
       "        [ 9.49754304,  6.83717231,  8.5372576 , 10.25507788],\n",
       "        [ 9.74781211,  7.08590736,  8.79172222, 10.51231889],\n",
       "        [10.10675099,  7.36233656,  9.04929544, 10.8330784 ],\n",
       "        [10.26403439,  7.49012477,  9.1990853 , 11.0009991 ],\n",
       "        [ 9.38079692,  6.64968823,  8.36287855, 10.12498269],\n",
       "        [ 8.38159361,  5.78871448,  7.47844778,  9.13821737],\n",
       "        [ 8.41135567,  5.68907736,  7.37831374,  9.12454445],\n",
       "        [ 8.32395501,  5.63936601,  7.32157781,  9.04300757],\n",
       "        [ 8.75774546,  6.0957045 ,  7.7980149 ,  9.5068838 ],\n",
       "        [ 9.76493753,  6.91526485,  8.60584616, 10.45792643],\n",
       "        [ 8.97744595,  6.26965767,  7.98644041,  9.72872948],\n",
       "        [ 9.4972545 ,  6.88414414,  8.61574836, 10.29826297],\n",
       "        [10.04211919,  7.35767143,  9.06544112, 10.80469092],\n",
       "        [ 9.41307606,  6.5848845 ,  8.25915008, 10.09265086],\n",
       "        [ 8.80645862,  6.184168  ,  7.89941385,  9.5816885 ],\n",
       "        [ 8.60147865,  5.83819092,  7.54291795,  9.31632243],\n",
       "        [ 8.83754847,  6.09084608,  7.77654539,  9.54808184],\n",
       "        [ 9.50149005,  6.81155599,  8.5168983 , 10.25500467],\n",
       "        [ 8.80448722,  6.10229048,  7.79884351,  9.53618498],\n",
       "        [ 7.70176138,  5.0219192 ,  6.71674196,  8.42181952],\n",
       "        [ 8.82248552,  6.10074868,  7.80496738,  9.55504771],\n",
       "        [ 8.91198629,  6.30319821,  8.00702721,  9.68425009],\n",
       "        [ 8.92339257,  6.26162828,  7.97103671,  9.68195428],\n",
       "        [ 9.34872505,  6.68427163,  8.38673002, 10.10542542],\n",
       "        [ 7.65573161,  5.06360198,  6.77676593,  8.41915254],\n",
       "        [ 8.84690301,  6.16624015,  7.87580825,  9.59762742],\n",
       "        [10.93024029,  8.02719257,  9.74712406, 11.64491567],\n",
       "        [ 9.72045141,  6.80912594,  8.5177524 , 10.40718722],\n",
       "        [11.22856926,  8.33510475, 10.03390541, 11.92982439],\n",
       "        [10.38291408,  7.5207842 ,  9.21081108, 11.07947807],\n",
       "        [10.78467997,  7.86949824,  9.57646568, 11.48204102],\n",
       "        [12.02966698,  9.11388449, 10.78726354, 12.71107419],\n",
       "        [ 8.63783646,  5.73303336,  7.44648076,  9.31504444],\n",
       "        [11.5316384 ,  8.65157265, 10.31618412, 12.21282237],\n",
       "        [10.74326111,  7.78797839,  9.45324256, 11.39284862],\n",
       "        [11.64211037,  8.80794516, 10.53686461, 12.39189846],\n",
       "        [10.30397937,  7.51287668,  9.24293418, 11.05364146],\n",
       "        [10.2596929 ,  7.34930725,  9.04967849, 10.94597256],\n",
       "        [10.76492029,  7.88740771,  9.60124882, 11.47835653],\n",
       "        [ 9.59786628,  6.61911528,  8.32971869, 10.26186135],\n",
       "        [ 9.90451458,  6.931667  ,  8.66863622, 10.59578439],\n",
       "        [10.45741961,  7.59974672,  9.33751079, 11.19381887],\n",
       "        [10.46750586,  7.63736193,  9.3356116 , 11.18140642],\n",
       "        [12.31589647,  9.54098019, 11.24310535, 13.06894952],\n",
       "        [12.31031825,  9.28092382, 10.93460312, 12.94232741],\n",
       "        [ 9.62213318,  6.6734472 ,  8.33823775, 10.25950262],\n",
       "        [11.05258103,  8.1784081 ,  9.90110668, 11.77780207],\n",
       "        [ 9.50179814,  6.60709978,  8.33328707, 10.20500448],\n",
       "        [12.11463254,  9.17410099, 10.83054261, 12.77495793],\n",
       "        [ 9.90535672,  7.03610229,  8.74619426, 10.60772518],\n",
       "        [10.8691691 ,  8.0480427 ,  9.76454967, 11.60537131],\n",
       "        [11.3067981 ,  8.50323367, 10.19024634, 12.02853181],\n",
       "        [ 9.78482858,  6.94569511,  8.66367283, 10.50201644],\n",
       "        [ 9.80606733,  7.00977891,  8.73112866, 10.54127779],\n",
       "        [10.52833771,  7.59105346,  9.29374927, 11.21172391],\n",
       "        [11.09774646,  8.29780351,  9.97281051, 11.80826508],\n",
       "        [11.48626657,  8.58051878, 10.25330998, 12.16463307],\n",
       "        [12.20862602,  9.48253832, 11.18507593, 12.97574292],\n",
       "        [10.56023231,  7.60620413,  9.3137957 , 11.24242825],\n",
       "        [ 9.95829128,  7.15921531,  8.84686029, 10.66738888],\n",
       "        [10.10159724,  7.24265553,  8.89355013, 10.76514614],\n",
       "        [11.83638937,  8.91530087, 10.61460608, 12.53412778],\n",
       "        [10.65018564,  7.80682558,  9.54240523, 11.3930233 ],\n",
       "        [10.41371803,  7.60645422,  9.30795112, 11.13751547],\n",
       "        [ 9.67349776,  6.8833406 ,  8.60859147, 10.41216366],\n",
       "        [10.78679521,  7.94069163,  9.66099471, 11.51556268],\n",
       "        [10.86960226,  7.95887547,  9.68650251, 11.58504534],\n",
       "        [10.66723846,  7.80873681,  9.5476624 , 11.40488524],\n",
       "        [ 9.72045141,  6.80912594,  8.5177524 , 10.40718722],\n",
       "        [11.1124861 ,  8.22608333,  9.94133513, 11.82906983],\n",
       "        [10.99769443,  8.1124587 ,  9.84675022, 11.72869998],\n",
       "        [10.57195357,  7.67784269,  9.41186772, 11.2934668 ],\n",
       "        [ 9.97699438,  7.03311825,  8.73692046, 10.65069747],\n",
       "        [10.33555535,  7.48806278,  9.20851141, 11.05925282],\n",
       "        [10.42119855,  7.60570516,  9.34444889, 11.17292572],\n",
       "        [ 9.79767444,  6.98536823,  8.69868237, 10.52213424]]),\n",
       " array([[ 6.82985724,  6.25199293,  5.13908542,  7.81251416,  7.46428527],\n",
       "        [ 6.5331496 ,  5.79204729,  4.67600794,  7.4497621 ,  6.99326245],\n",
       "        [ 6.3691352 ,  5.74424896,  4.64659775,  7.32690878,  6.95681381],\n",
       "        [ 6.34496174,  5.63518305,  4.52098372,  7.27985739,  6.8555541 ],\n",
       "        [ 6.77449583,  6.23952416,  5.1318327 ,  7.77390918,  7.45825576],\n",
       "        [ 7.36453016,  6.77197311,  5.61213527,  8.37189757,  8.0100059 ],\n",
       "        [ 6.40393558,  5.80703855,  4.69367979,  7.38702931,  7.04118476],\n",
       "        [ 6.75794037,  6.12751169,  5.00733728,  7.72503546,  7.3435964 ],\n",
       "        [ 6.08724987,  5.34167873,  4.23912291,  7.00157884,  6.55887174],\n",
       "        [ 6.5770784 ,  5.8729672 ,  4.76536098,  7.50506038,  7.07371338],\n",
       "        [ 7.18198974,  6.62099018,  5.49614043,  8.17655319,  7.83314715],\n",
       "        [ 6.63320511,  5.99246439,  4.87054025,  7.60100353,  7.21881473],\n",
       "        [ 6.426591  ,  5.71934538,  4.62185052,  7.34730253,  6.91615892],\n",
       "        [ 5.87546052,  5.29617716,  4.24791321,  6.82751131,  6.49874165],\n",
       "        [ 7.5101698 ,  7.0815887 ,  5.97545868,  8.54049548,  8.27903677],\n",
       "        [ 7.70789286,  7.29025011,  6.14971952,  8.77198073,  8.52501174],\n",
       "        [ 7.2108884 ,  6.71565245,  5.58527356,  8.23656024,  7.94016082],\n",
       "        [ 6.85111842,  6.24787779,  5.12108554,  7.83230817,  7.46761033],\n",
       "        [ 7.56430983,  6.94143288,  5.78547284,  8.55181635,  8.16003388],\n",
       "        [ 6.98129628,  6.45396315,  5.32653038,  7.99694492,  7.68584646],\n",
       "        [ 7.17982222,  6.47144277,  5.32698198,  8.12562327,  7.67962844],\n",
       "        [ 6.97226144,  6.38667492,  5.24342505,  7.97346149,  7.62292888],\n",
       "        [ 6.28442584,  5.90073501,  4.84582355,  7.31848422,  7.11479261],\n",
       "        [ 6.96815843,  6.16989896,  4.98841298,  7.90384588,  7.40704748],\n",
       "        [ 6.76970861,  6.05221888,  4.90894575,  7.72082009,  7.28675625],\n",
       "        [ 6.70312154,  5.90389421,  4.76903249,  7.60718441,  7.1081331 ],\n",
       "        [ 6.84407435,  6.13705386,  4.98088932,  7.80304148,  7.37131041],\n",
       "        [ 6.95463129,  6.34315873,  5.21954253,  7.92929636,  7.55558607],\n",
       "        [ 6.88767785,  6.2676287 ,  5.15021272,  7.85347637,  7.4729867 ],\n",
       "        [ 6.49734006,  5.79103791,  4.66759647,  7.43904567,  7.01446997],\n",
       "        [ 6.55656801,  5.80619273,  4.67770766,  7.48071614,  7.02230478],\n",
       "        [ 7.14086116,  6.43248616,  5.27607644,  8.09328294,  7.64846203],\n",
       "        [ 7.12584552,  6.73517722,  5.63832713,  8.1775515 ,  7.95702675],\n",
       "        [ 7.39228898,  7.00348968,  5.89400399,  8.44831824,  8.22293761],\n",
       "        [ 6.5770784 ,  5.8729672 ,  4.76536098,  7.50506038,  7.07371338],\n",
       "        [ 6.58682999,  5.96502349,  4.8672749 ,  7.53995607,  7.16220612],\n",
       "        [ 7.13564954,  6.55140166,  5.43671989,  8.10981812,  7.74585753],\n",
       "        [ 6.5770784 ,  5.8729672 ,  4.76536098,  7.50506038,  7.07371338],\n",
       "        [ 6.06644086,  5.38945348,  4.29868648,  7.00249125,  6.60629464],\n",
       "        [ 6.84250365,  6.20441282,  5.08150141,  7.80657415,  7.41695519],\n",
       "        [ 6.72739751,  6.15854934,  5.04302408,  7.71665005,  7.37793181],\n",
       "        [ 6.05013081,  5.05321809,  3.93269487,  6.8627975 ,  6.24225205],\n",
       "        [ 6.11682832,  5.51827682,  4.43240127,  7.08408857,  6.74157326],\n",
       "        [ 6.92098571,  6.19944657,  5.0193259 ,  7.88996308,  7.45039304],\n",
       "        [ 7.17277941,  6.52241011,  5.35425304,  8.16630553,  7.77276823],\n",
       "        [ 6.47014832,  5.70859301,  4.57953475,  7.38797685,  6.92188941],\n",
       "        [ 7.00124791,  6.47340614,  5.35180373,  8.0133258 ,  7.70136979],\n",
       "        [ 6.32658148,  5.68225   ,  4.57906499,  7.28210829,  6.90238744],\n",
       "        [ 7.09724442,  6.54440005,  5.42211487,  8.09503521,  7.75985684],\n",
       "        [ 6.69051327,  6.0509426 ,  4.93705312,  7.6484981 ,  7.25996263],\n",
       "        [10.23442552,  8.7090643 ,  7.37160897, 10.99242134,  9.92809992],\n",
       "        [ 9.69711576,  8.16985387,  6.82174222, 10.46138451,  9.41184894],\n",
       "        [10.28916886,  8.70030196,  7.35828513, 11.02704548,  9.91756932],\n",
       "        [ 8.56386036,  6.84408739,  5.50834319,  9.23261998,  8.06350673],\n",
       "        [ 9.77170572,  8.12677172,  6.78193491, 10.48523127,  9.34360019],\n",
       "        [ 9.07710591,  7.45792705,  6.12804784,  9.79169925,  8.68979439],\n",
       "        [ 9.79139766,  8.25222004,  6.89981042, 10.55710179,  9.50155748],\n",
       "        [ 7.6206626 ,  6.0662215 ,  4.7522501 ,  8.33515741,  7.31078417],\n",
       "        [ 9.80568841,  8.22120552,  6.89100663, 10.53336926,  9.43287986],\n",
       "        [ 8.36171054,  6.75540591,  5.40760843,  9.08617534,  8.01399986],\n",
       "        [ 7.78309226,  6.06439261,  4.75473979,  8.42770988,  7.27571573],\n",
       "        [ 9.12031439,  7.56438516,  6.21224242,  9.87234495,  8.81575908],\n",
       "        [ 8.84537347,  7.16693506,  5.86372763,  9.50787424,  8.34939714],\n",
       "        [ 9.52899556,  7.90790708,  6.57155511, 10.24896786,  9.1347305 ],\n",
       "        [ 8.47065884,  6.99326462,  5.65258523,  9.23949328,  8.25020966],\n",
       "        [ 9.81767206,  8.29520794,  6.95461036, 10.57608263,  9.5215728 ],\n",
       "        [ 9.09392022,  7.49897525,  6.1532798 ,  9.83055043,  8.75183926],\n",
       "        [ 8.80653131,  7.2588645 ,  5.94985095,  9.53007462,  8.47699907],\n",
       "        [ 9.43209616,  7.62390862,  6.28508785, 10.07276406,  8.81412859],\n",
       "        [ 8.53885769,  6.93238854,  5.61263917,  9.24261016,  8.15357768],\n",
       "        [ 9.61591021,  8.00313845,  6.64052394, 10.36114181,  9.26192737],\n",
       "        [ 9.06228465,  7.50962662,  6.17251269,  9.80119393,  8.73963616],\n",
       "        [ 9.77879109,  8.01808638,  6.68225666, 10.44264755,  9.21652002],\n",
       "        [ 9.46271985,  7.84635499,  6.52694127, 10.17237834,  9.05931355],\n",
       "        [ 9.47743553,  7.92286679,  6.58892453, 10.21680995,  9.14483787],\n",
       "        [ 9.72726295,  8.17615745,  6.83554223, 10.47389054,  9.40024957],\n",
       "        [10.08788134,  8.44515781,  7.11156827, 10.79599715,  9.6466929 ],\n",
       "        [10.24409358,  8.58621113,  7.23256485, 10.96400692,  9.80854308],\n",
       "        [ 9.360707  ,  7.74308729,  6.39546981, 10.08765169,  8.9807079 ],\n",
       "        [ 8.362348  ,  6.86226943,  5.55045822,  9.09942664,  8.0865812 ],\n",
       "        [ 8.39375972,  6.76588344,  5.44559963,  9.08750602,  7.98602919],\n",
       "        [ 8.30629161,  6.71034346,  5.39944829,  9.00561802,  7.92707402],\n",
       "        [ 8.73825181,  7.17972287,  5.8498694 ,  9.46878016,  8.41081397],\n",
       "        [ 9.74673868,  7.99863987,  6.65890749, 10.42269541,  9.2145615 ],\n",
       "        [ 8.95651654,  7.35920864,  6.01551266,  9.69158746,  8.61678932],\n",
       "        [ 9.47409199,  7.98291223,  6.62918104, 10.25933518,  9.24807907],\n",
       "        [10.0213324 ,  8.4497787 ,  7.10475261, 10.76656889,  9.6755118 ],\n",
       "        [ 9.39680172,  7.66210652,  6.33628166, 10.05685999,  8.8496729 ],\n",
       "        [ 8.78511494,  7.27171749,  5.93560734,  9.5431981 ,  8.52533582],\n",
       "        [ 8.583332  ,  6.92579977,  5.58831998,  9.27958506,  8.15756225],\n",
       "        [ 8.81924313,  7.1645208 ,  5.84367362,  9.51175499,  8.38826881],\n",
       "        [ 9.48097306,  7.89858668,  6.56002126, 10.21734406,  9.13277788],\n",
       "        [ 8.78578118,  7.18440974,  5.85597383,  9.49868518,  8.40817824],\n",
       "        [ 7.68424717,  6.09711384,  4.78313423,  8.38430453,  7.3319534 ],\n",
       "        [ 8.80325319,  7.18609962,  5.85110387,  9.51790026,  8.42207453],\n",
       "        [ 8.89085582,  7.38360081,  6.05718925,  9.64579284,  8.62803731],\n",
       "        [ 8.90287869,  7.34802947,  6.01258031,  9.64397634,  8.5918471 ],\n",
       "        [ 9.32853621,  7.77014415,  6.43564035, 10.06729116,  8.99791239],\n",
       "        [ 7.63629267,  6.14793818,  4.82429379,  8.38011231,  7.39933489],\n",
       "        [ 8.82691671,  7.25403639,  5.91710983,  9.55979236,  8.49461511],\n",
       "        [10.90950773,  9.12989547,  7.75711204, 11.61010898, 10.37290083],\n",
       "        [ 9.70213068,  7.90488745,  6.54603267, 10.37249953,  9.13517705],\n",
       "        [11.20954839,  9.43025953,  8.07161352, 11.89459019, 10.63738554],\n",
       "        [10.36407651,  8.60494565,  7.26153065, 11.04446992,  9.81957855],\n",
       "        [10.76542668,  8.96707388,  7.60339979, 11.4472901 , 10.19010371],\n",
       "        [12.01138641, 10.19562876,  8.85259634, 12.67663062, 11.37838402],\n",
       "        [ 8.62007746,  6.82572   ,  5.47240263,  9.28065253,  8.07527545],\n",
       "        [11.51364413,  9.72562778,  8.39455144, 12.17818293, 10.90558826],\n",
       "        [10.72690091,  8.86385475,  7.52981982, 11.35918316, 10.04296   ],\n",
       "        [11.62019434,  9.9180495 ,  8.53892645, 12.35550693, 11.15838019],\n",
       "        [10.28287948,  8.62073696,  7.24928686, 11.01666819,  9.86534463],\n",
       "        [10.24166125,  8.44376075,  7.08733474, 10.91105776,  9.65636457],\n",
       "        [10.74543101,  8.99028063,  7.62269465, 11.44265049, 10.21232011],\n",
       "        [ 9.5806254 ,  7.71896298,  6.3533425 , 10.2279338 ,  8.94561914],\n",
       "        [ 9.88547673,  8.04752367,  6.65889423, 10.5613365 ,  9.29691063],\n",
       "        [10.43646635,  8.714027  ,  7.3307759 , 11.15766302,  9.96434529],\n",
       "        [10.44803196,  8.72665141,  7.37799631, 11.14566946,  9.94555607],\n",
       "        [12.29389114, 10.63335955,  9.27831384, 13.0323716 , 11.85374721],\n",
       "        [12.29418667, 10.35594954,  9.01820177, 12.90967437, 11.51364001],\n",
       "        [ 9.60694972,  7.7464085 ,  6.41964535, 10.22582035,  8.93004935],\n",
       "        [11.03221254,  9.28631217,  7.91089162, 11.7419472 , 10.51742832],\n",
       "        [ 9.48257679,  7.71180251,  6.34135231, 10.16987746,  8.96054111],\n",
       "        [12.09746222, 10.24721237,  8.91510479, 12.74112343, 11.41243264],\n",
       "        [ 9.8869237 ,  8.13514372,  6.7753955 , 10.5720072 ,  9.35622095],\n",
       "        [10.84825847,  9.14846316,  7.78388386, 11.56917611, 10.38288052],\n",
       "        [11.28694751,  9.58736294,  8.24535574, 11.99249953, 10.79175752],\n",
       "        [ 9.7656672 ,  8.04766435,  6.68478097, 10.46583425,  9.2790293 ],\n",
       "        [ 9.78580042,  8.11058819,  6.74912867, 10.50469527,  9.35263385],\n",
       "        [10.50998855,  8.68714725,  7.32599986, 11.17725595,  9.90368854],\n",
       "        [11.07880212,  9.37525569,  8.04346869, 11.7723149 , 10.56693097],\n",
       "        [11.46858032,  9.66190121,  8.32153311, 12.12994867, 10.84225345],\n",
       "        [12.18641307, 10.57488377,  9.2226539 , 12.93833096, 11.79288455],\n",
       "        [10.54185624,  8.70603749,  7.33931823, 11.20806515,  9.92535622],\n",
       "        [ 9.93958136,  8.24058739,  6.90537169, 10.63141104,  9.45197245],\n",
       "        [10.08462021,  8.30159087,  6.99220148, 10.73101235,  9.48795929],\n",
       "        [11.81761431, 10.01482738,  8.6499336 , 12.49892228, 11.21192165],\n",
       "        [10.62845398,  8.91736414,  7.53726909, 11.35702101, 10.17380076],\n",
       "        [10.39366229,  8.69590081,  7.34713124, 11.10154197,  9.92190052],\n",
       "        [ 9.65307948,  7.98582455,  6.62248537, 10.37546431,  9.23257459],\n",
       "        [10.76668377,  9.04688686,  7.67608273, 11.47926194, 10.27417289],\n",
       "        [10.84958989,  9.07055587,  7.68909172, 11.54961012, 10.3052882 ],\n",
       "        [10.64676863,  8.92768506,  7.54037772, 11.36824498, 10.16623808],\n",
       "        [ 9.70213068,  7.90488745,  6.54603267, 10.37249953,  9.13517705],\n",
       "        [11.09230868,  9.32883008,  7.95891746, 11.79367496, 10.55701201],\n",
       "        [10.97671202,  9.2265174 ,  7.84156366, 11.69292653, 10.47104606],\n",
       "        [10.55207999,  8.79398689,  7.40893339, 11.25750249, 10.03007648],\n",
       "        [ 9.95982421,  8.13165803,  6.77045213, 10.61600296,  9.34191356],\n",
       "        [10.31569555,  8.59254581,  7.22425635, 11.02313417,  9.82485897],\n",
       "        [10.39920024,  8.71680371,  7.33733511, 11.13651441,  9.97781219],\n",
       "        [ 9.77759633,  8.07989967,  6.7249289 , 10.48616425,  9.32111303]]),\n",
       " array([[ 7.81251416,  5.48143583,  7.46428527,  6.37952703,  6.82985724,\n",
       "          4.66120186],\n",
       "        [ 7.4497621 ,  5.03195827,  6.99326245,  5.91682645,  6.5331496 ,\n",
       "          4.17515523],\n",
       "        [ 7.32690878,  4.98099618,  6.95681381,  5.87189809,  6.3691352 ,\n",
       "          4.18282852],\n",
       "        [ 7.27985739,  4.86548573,  6.8555541 ,  5.76251881,  6.34496174,\n",
       "          4.04305157],\n",
       "        [ 7.77390918,  5.46624786,  7.45825576,  6.36828168,  6.77449583,\n",
       "          4.66790688],\n",
       "        [ 8.37189757,  5.96768316,  8.0100059 ,  6.90116434,  7.36453016,\n",
       "          5.12389841],\n",
       "        [ 7.38702931,  5.02355595,  7.04118476,  5.93711373,  6.40393558,\n",
       "          4.24533427],\n",
       "        [ 7.72503546,  5.35453381,  7.3435964 ,  6.25482695,  6.75794037,\n",
       "          4.5228358 ],\n",
       "        [ 7.00157884,  4.57925038,  6.55887174,  5.46871014,  6.08724987,\n",
       "          3.76853236],\n",
       "        [ 7.50506038,  5.11767304,  7.07371338,  5.99802661,  6.5770784 ,\n",
       "          4.26660136],\n",
       "        [ 8.17655319,  5.84543525,  7.83314715,  6.74826625,  7.18198974,\n",
       "          5.00657782],\n",
       "        [ 7.60100353,  5.21436983,  7.21881473,  6.12078439,  6.63320511,\n",
       "          4.39406834],\n",
       "        [ 7.34730253,  4.96990958,  6.91615892,  5.84422249,  6.426591  ,\n",
       "          4.12930829],\n",
       "        [ 6.82751131,  4.55730301,  6.49874165,  5.42416956,  5.87546052,\n",
       "          3.82038361],\n",
       "        [ 8.54049548,  6.31458548,  8.27903677,  7.2087802 ,  7.5101698 ,\n",
       "          5.4984259 ],\n",
       "        [ 8.77198073,  6.48867202,  8.52501174,  7.42095797,  7.70789286,\n",
       "          5.68523211],\n",
       "        [ 8.23656024,  5.92471966,  7.94016082,  6.84502052,  7.2108884 ,\n",
       "          5.11961449],\n",
       "        [ 7.83230817,  5.46691726,  7.46761033,  6.37584223,  6.85111842,\n",
       "          4.64251528],\n",
       "        [ 8.55181635,  6.15122624,  8.16003388,  7.06811313,  7.56430983,\n",
       "          5.27397528],\n",
       "        [ 7.99694492,  5.6643421 ,  7.68584646,  6.58383955,  6.98129628,\n",
       "          4.86264753],\n",
       "        [ 8.12562327,  5.69602763,  7.67962844,  6.59638846,  7.17982222,\n",
       "          4.80586519],\n",
       "        [ 7.97346149,  5.58860743,  7.62292888,  6.51631769,  6.97226144,\n",
       "          4.77224744],\n",
       "        [ 7.31848422,  5.14302416,  7.11479261,  6.03155447,  6.28442584,\n",
       "          4.44152192],\n",
       "        [ 7.90384588,  5.36245391,  7.40704748,  6.29691135,  6.96815843,\n",
       "          4.47592102],\n",
       "        [ 7.72082009,  5.26524997,  7.28675625,  6.18003431,  6.76970861,\n",
       "          4.41483276],\n",
       "        [ 7.60718441,  5.13766785,  7.1081331 ,  6.02790317,  6.70312154,\n",
       "          4.24834688],\n",
       "        [ 7.80304148,  5.33955601,  7.37131041,  6.26512562,  6.84407435,\n",
       "          4.48879772],\n",
       "        [ 7.92929636,  5.56986811,  7.55558607,  6.47010091,  6.95463129,\n",
       "          4.72888593],\n",
       "        [ 7.85347637,  5.50021926,  7.4729867 ,  6.39388136,  6.88767785,\n",
       "          4.65878212],\n",
       "        [ 7.43904567,  5.01632609,  7.01446997,  5.91844656,  6.49734006,\n",
       "          4.18317657],\n",
       "        [ 7.48071614,  5.03485854,  7.02230478,  5.93223089,  6.55656801,\n",
       "          4.17808739],\n",
       "        [ 8.09328294,  5.64370024,  7.64846203,  6.5583883 ,  7.14086116,\n",
       "          4.7651537 ],\n",
       "        [ 8.1775515 ,  5.96171867,  7.95702675,  6.86545579,  7.12584552,\n",
       "          5.18835827],\n",
       "        [ 8.44831824,  6.22393412,  8.22293761,  7.13335732,  7.39228898,\n",
       "          5.43554446],\n",
       "        [ 7.50506038,  5.11767304,  7.07371338,  5.99802661,  6.5770784 ,\n",
       "          4.26660136],\n",
       "        [ 7.53995607,  5.20876758,  7.16220612,  6.09089037,  6.58682999,\n",
       "          4.38849067],\n",
       "        [ 8.10981812,  5.7884914 ,  7.74585753,  6.67675245,  7.13564954,\n",
       "          4.94005947],\n",
       "        [ 7.50506038,  5.11767304,  7.07371338,  5.99802661,  6.5770784 ,\n",
       "          4.26660136],\n",
       "        [ 7.00249125,  4.62872372,  6.60629464,  5.51737218,  6.06644086,\n",
       "          3.84421726],\n",
       "        [ 7.80657415,  5.432365  ,  7.41695519,  6.33117366,  6.84250365,\n",
       "          4.59027587],\n",
       "        [ 7.71665005,  5.38051042,  7.37793181,  6.28709182,  6.72739751,\n",
       "          4.57792406],\n",
       "        [ 6.8627975 ,  4.30496198,  6.24225205,  5.1742122 ,  6.05013081,\n",
       "          3.4086295 ],\n",
       "        [ 7.08408857,  4.75306757,  6.74157326,  5.64769758,  6.11682832,\n",
       "          3.99403153],\n",
       "        [ 7.88996308,  5.38017042,  7.45039304,  6.32892907,  6.92098571,\n",
       "          4.53417429],\n",
       "        [ 8.16630553,  5.71110815,  7.77276823,  6.65219555,  7.17277941,\n",
       "          4.86778889],\n",
       "        [ 7.38797685,  4.93579705,  6.92188941,  5.83446095,  6.47014832,\n",
       "          4.0845413 ],\n",
       "        [ 8.0133258 ,  5.69047103,  7.70136979,  6.60279374,  7.00124791,\n",
       "          4.88263927],\n",
       "        [ 7.28210829,  4.91411239,  6.90238744,  5.81044132,  6.32658148,\n",
       "          4.11611907],\n",
       "        [ 8.09503521,  5.76797678,  7.75985684,  6.67219586,  7.09724442,\n",
       "          4.93874808],\n",
       "        [ 7.6484981 ,  5.2839392 ,  7.25996263,  6.17757017,  6.69051327,\n",
       "          4.45173363],\n",
       "        [10.99242134,  7.85847759,  9.92809992,  8.81906215, 10.23442552,\n",
       "          6.71701884],\n",
       "        [10.46138451,  7.30232175,  9.41184894,  8.28236538,  9.69711576,\n",
       "          6.18506371],\n",
       "        [11.02704548,  7.84852496,  9.91756932,  8.80887576, 10.28916886,\n",
       "          6.70333491],\n",
       "        [ 9.23261998,  5.99979718,  8.06350673,  6.95204011,  8.56386036,\n",
       "          4.8510105 ],\n",
       "        [10.48523127,  7.27516726,  9.34360019,  8.23475758,  9.77170572,\n",
       "          6.12388843],\n",
       "        [ 9.79169925,  6.60694899,  8.68979439,  7.56803117,  9.07710591,\n",
       "          5.49290791],\n",
       "        [10.55710179,  7.37794992,  9.50155748,  8.36499272,  9.79139766,\n",
       "          6.27261123],\n",
       "        [ 8.33515741,  5.2197918 ,  7.31078417,  6.18089206,  7.6206626 ,\n",
       "          4.12270304],\n",
       "        [10.53336926,  7.37962117,  9.43287986,  8.32968668,  9.80568841,\n",
       "          6.23229078],\n",
       "        [ 9.08617534,  5.88178048,  8.01399986,  6.86938171,  8.36171054,\n",
       "          4.78772119],\n",
       "        [ 8.42770988,  5.24100343,  7.27571573,  6.17252166,  7.78309226,\n",
       "          4.0920224 ],\n",
       "        [ 9.87234495,  6.6907656 ,  8.81575908,  7.67783582,  9.12031439,\n",
       "          5.58255099],\n",
       "        [ 9.50787424,  6.35758847,  8.34939714,  7.27178226,  8.84537347,\n",
       "          5.18359627],\n",
       "        [10.24896786,  7.05548036,  9.1347305 ,  8.01717665,  9.52899556,\n",
       "          5.92921749],\n",
       "        [ 9.23949328,  6.12257204,  8.25020966,  7.10952   ,  8.47065884,\n",
       "          5.02850416],\n",
       "        [10.57608263,  7.43979233,  9.5215728 ,  8.40635411,  9.81767206,\n",
       "          6.30353258],\n",
       "        [ 9.83055043,  6.62728279,  8.75183926,  7.61152326,  9.09392022,\n",
       "          5.53570418],\n",
       "        [ 9.53007462,  6.42681663,  8.47699907,  7.36937508,  8.80653131,\n",
       "          5.30161928],\n",
       "        [10.07276406,  6.79057787,  8.81412859,  7.72659795,  9.43209616,\n",
       "          5.6084247 ],\n",
       "        [ 9.24261016,  6.09457672,  8.15357768,  7.0425787 ,  8.53885769,\n",
       "          4.96063625],\n",
       "        [10.36114181,  7.11775655,  9.26192737,  8.1154727 ,  9.61591021,\n",
       "          6.02689113],\n",
       "        [ 9.80119393,  6.6559244 ,  8.73963616,  7.62128536,  9.06228465,\n",
       "          5.52318204],\n",
       "        [10.44264755,  7.18068914,  9.21652002,  8.12192201,  9.77879109,\n",
       "          6.0186644 ],\n",
       "        [10.17237834,  7.01030868,  9.05931355,  7.9543433 ,  9.46271985,\n",
       "          5.87760058],\n",
       "        [10.21680995,  7.07435437,  9.14483787,  8.03324706,  9.47743553,\n",
       "          5.9354325 ],\n",
       "        [10.47389054,  7.32240867,  9.40024957,  8.28663645,  9.72726295,\n",
       "          6.18245852],\n",
       "        [10.79599715,  7.60665198,  9.6466929 ,  8.55142177, 10.08788134,\n",
       "          6.44527515],\n",
       "        [10.96400692,  7.72572144,  9.80854308,  8.69401434, 10.24409358,\n",
       "          6.58191779],\n",
       "        [10.08765169,  6.87937657,  8.9807079 ,  7.85374682,  9.360707  ,\n",
       "          5.75718989],\n",
       "        [ 9.09942664,  6.02533997,  8.0865812 ,  6.97506977,  8.362348  ,\n",
       "          4.90200101],\n",
       "        [ 9.08750602,  5.92902094,  7.98602919,  6.87579291,  8.39375972,\n",
       "          4.79115975],\n",
       "        [ 9.00561802,  5.88000926,  7.92707402,  6.82060029,  8.30629161,\n",
       "          4.74426979],\n",
       "        [ 9.46878016,  6.33013377,  8.41081397,  7.2916257 ,  8.73825181,\n",
       "          5.20360611],\n",
       "        [10.42269541,  7.14889561,  9.2145615 ,  8.10412802,  9.74673868,\n",
       "          6.01688646],\n",
       "        [ 9.69158746,  6.48550405,  8.61678932,  7.47218086,  8.95651654,\n",
       "          5.40692547],\n",
       "        [10.25933518,  7.09882299,  9.24807907,  8.09827565,  9.47409199,\n",
       "          6.0180632 ],\n",
       "        [10.76656889,  7.59241464,  9.6755118 ,  8.55970858, 10.0213324 ,\n",
       "          6.45473315],\n",
       "        [10.05685999,  6.83702882,  8.8496729 ,  7.76593992,  9.39680172,\n",
       "          5.65799399],\n",
       "        [ 9.5431981 ,  6.40529833,  8.52533582,  7.38630658,  8.78511494,\n",
       "          5.31487043],\n",
       "        [ 9.27958506,  6.07323096,  8.15756225,  7.03604675,  8.583332  ,\n",
       "          4.94232581],\n",
       "        [ 9.51175499,  6.32355217,  8.38826881,  7.27339428,  8.81924313,\n",
       "          5.20398522],\n",
       "        [10.21734406,  7.04097666,  9.13277788,  8.00935245,  9.48097306,\n",
       "          5.92214406],\n",
       "        [ 9.49868518,  6.33995618,  8.40817824,  7.29473784,  8.78578118,\n",
       "          5.2039741 ],\n",
       "        [ 8.38430453,  5.25666239,  7.3319534 ,  6.2102158 ,  7.68424717,\n",
       "          4.14175427],\n",
       "        [ 9.51790026,  6.33132919,  8.42207453,  7.2971109 ,  8.80325319,\n",
       "          5.21319441],\n",
       "        [ 9.64579284,  6.52718109,  8.62803731,  7.49722392,  8.89085582,\n",
       "          5.43113817],\n",
       "        [ 9.64397634,  6.48782356,  8.5918471 ,  7.46081895,  8.90287869,\n",
       "          5.38203181],\n",
       "        [10.06729116,  6.91862525,  8.99791239,  7.88106965,  9.32853621,\n",
       "          5.78793411],\n",
       "        [ 8.38011231,  5.29022362,  7.39933489,  6.26473851,  7.63629267,\n",
       "          4.19836069],\n",
       "        [ 9.55979236,  6.39537612,  8.49461511,  7.36636494,  8.82691671,\n",
       "          5.28092369],\n",
       "        [11.61010898,  8.24100166, 10.37290083,  9.2362506 , 10.90950773,\n",
       "          7.15357095],\n",
       "        [10.37249953,  7.03638621,  9.13517705,  8.01087314,  9.70213068,\n",
       "          5.91710918],\n",
       "        [11.89459019,  8.57139408, 10.63738554,  9.53351708, 11.20954839,\n",
       "          7.42248704],\n",
       "        [11.04446992,  7.75130399,  9.81957855,  8.70949967, 10.36407651,\n",
       "          6.62556521],\n",
       "        [11.4472901 ,  8.09658966, 10.19010371,  9.07152731, 10.76542668,\n",
       "          6.97358986],\n",
       "        [12.67663062,  9.35471679, 11.37838402, 10.29529175, 12.01138641,\n",
       "          8.19713682],\n",
       "        [ 9.28065253,  5.95144081,  8.07527545,  6.93449751,  8.62007746,\n",
       "          4.86502679],\n",
       "        [12.17818293,  8.89395465, 10.90558826,  9.82572987, 11.51364413,\n",
       "          7.73632968],\n",
       "        [11.35918316,  8.03263815, 10.04296   ,  8.9629616 , 10.72690091,\n",
       "          6.86948672],\n",
       "        [12.35550693,  9.02926964, 11.15838019, 10.0255674 , 11.62019434,\n",
       "          7.91563452],\n",
       "        [11.01666819,  7.73790005,  9.86534463,  8.73047055, 10.28287948,\n",
       "          6.61862163],\n",
       "        [10.91105776,  7.58574609,  9.65636457,  8.54782829, 10.24166125,\n",
       "          6.43907255],\n",
       "        [11.44265049,  8.12029467, 10.21232011,  9.09579493, 10.74543101,\n",
       "          6.9789444 ],\n",
       "        [10.2279338 ,  6.84893542,  8.94561914,  7.82356407,  9.5806254 ,\n",
       "          5.72088153],\n",
       "        [10.5613365 ,  7.15047153,  9.29691063,  8.15454656,  9.88547673,\n",
       "          6.0464906 ],\n",
       "        [11.15766302,  7.82011167,  9.96434529,  8.82298674, 10.43646635,\n",
       "          6.71058422],\n",
       "        [11.14566946,  7.86875957,  9.94555607,  8.83242827, 10.44803196,\n",
       "          6.73820913],\n",
       "        [13.0323716 ,  9.76705362, 11.85374721, 10.7391918 , 12.29389114,\n",
       "          8.64591714],\n",
       "        [12.90967437,  9.52745732, 11.51364001, 10.45076878, 12.29418667,\n",
       "          8.35669075],\n",
       "        [10.22582035,  6.92109151,  8.93004935,  7.84686056,  9.60694972,\n",
       "          5.75413789],\n",
       "        [11.7419472 ,  8.40612109, 10.51742832,  9.39262247, 11.03221254,\n",
       "          7.27659036],\n",
       "        [10.16987746,  6.82718657,  8.96054111,  7.82029107,  9.48257679,\n",
       "          5.72576181],\n",
       "        [12.74112343,  9.42021255, 11.41243264, 10.3445049 , 12.09746222,\n",
       "          8.2515565 ],\n",
       "        [10.5720072 ,  7.27268874,  9.35622095,  8.2413413 ,  9.8869237 ,\n",
       "          6.12511541],\n",
       "        [11.56917611,  8.27254194, 10.38288052,  9.25586871, 10.84825847,\n",
       "          7.15572775],\n",
       "        [11.99249953,  8.7389656 , 10.79175752,  9.69163988, 11.28694751,\n",
       "          7.5963622 ],\n",
       "        [10.46583425,  7.17830019,  9.2790293 ,  8.15557551,  9.7656672 ,\n",
       "          6.04140879],\n",
       "        [10.50469527,  7.23551929,  9.35263385,  8.22013049,  9.78580042,\n",
       "          6.11876486],\n",
       "        [11.17725595,  7.82253945,  9.90368854,  8.79077557, 10.50998855,\n",
       "          6.68834797],\n",
       "        [11.7723149 ,  8.53963645, 10.56693097,  9.47844458, 11.07880212,\n",
       "          7.38350901],\n",
       "        [12.12994867,  8.82577353, 10.84225345,  9.76193825, 11.46858032,\n",
       "          7.65718285],\n",
       "        [12.93833096,  9.71283455, 11.79288455, 10.68163   , 12.18641307,\n",
       "          8.58055117],\n",
       "        [11.20806515,  7.83665548,  9.92535622,  8.80969546, 10.54185624,\n",
       "          6.70374104],\n",
       "        [10.63141104,  7.39578383,  9.45197245,  8.34650449,  9.93958136,\n",
       "          6.25601188],\n",
       "        [10.73101235,  7.48061257,  9.48795929,  8.40291323, 10.08462021,\n",
       "          6.34609588],\n",
       "        [12.49892228,  9.15662059, 11.21192165, 10.11658173, 11.81761431,\n",
       "          7.99093729],\n",
       "        [11.35702101,  8.01968874, 10.17380076,  9.0266887 , 10.62845398,\n",
       "          6.9325818 ],\n",
       "        [11.10154197,  7.83397115,  9.92190052,  8.80275159, 10.39366229,\n",
       "          6.71461199],\n",
       "        [10.37546431,  7.10742199,  9.23257459,  8.09609194,  9.65307948,\n",
       "          5.9953085 ],\n",
       "        [11.47926194,  8.1727775 , 10.27417289,  9.15363263, 10.76668377,\n",
       "          7.03252614],\n",
       "        [11.54961012,  8.18497307, 10.3052882 ,  9.17671344, 10.84958989,\n",
       "          7.05886843],\n",
       "        [11.36824498,  8.03885432, 10.16623808,  9.03582679, 10.64676863,\n",
       "          6.89969586],\n",
       "        [10.37249953,  7.03638621,  9.13517705,  8.01087314,  9.70213068,\n",
       "          5.91710918],\n",
       "        [11.79367496,  8.45214673, 10.55701201,  9.43431708, 11.09230868,\n",
       "          7.32912816],\n",
       "        [11.69292653,  8.33301462, 10.47104606,  9.33397566, 10.97671202,\n",
       "          7.22142791],\n",
       "        [11.25750249,  7.9074974 , 10.03007648,  8.90111011, 10.55207999,\n",
       "          6.77055796],\n",
       "        [10.61600296,  7.2735283 ,  9.34191356,  8.23532356,  9.95982421,\n",
       "          6.11472593],\n",
       "        [11.02313417,  7.71791836,  9.82485897,  8.6999405 , 10.31569555,\n",
       "          6.58580605],\n",
       "        [11.13651441,  7.81788559,  9.97781219,  8.82730585, 10.39920024,\n",
       "          6.73335095],\n",
       "        [10.48616425,  7.20757203,  9.32111303,  8.188689  ,  9.77759633,\n",
       "          6.10344549]]),\n",
       " array([[ 4.66120186,  8.0255182 ,  6.35860204, ...,  7.46428527,\n",
       "          6.57462997,  5.44571778],\n",
       "        [ 4.17515523,  7.65309309,  5.8966715 , ...,  6.99326245,\n",
       "          6.30653384,  4.99595284],\n",
       "        [ 4.18282852,  7.53737734,  5.85102605, ...,  6.95681381,\n",
       "          6.12725168,  4.94568632],\n",
       "        ...,\n",
       "        [ 6.58580605, 11.191882  ,  8.67599476, ...,  9.82485897,\n",
       "         10.14045532,  7.68072257],\n",
       "        [ 6.73335095, 11.31155001,  8.80172416, ...,  9.97781219,\n",
       "         10.21199063,  7.78117351],\n",
       "        [ 6.10344549, 10.6566515 ,  8.1640531 , ...,  9.32111303,\n",
       "          9.60220377,  7.17151155]]),\n",
       " array([[ 6.60486906,  6.57538129,  5.78929057, ...,  4.70321027,\n",
       "          7.28431854,  5.32958107],\n",
       "        [ 6.33403352,  6.11811293,  5.32495397, ...,  4.21159091,\n",
       "          6.94942029,  4.89031754],\n",
       "        [ 6.15595258,  6.06691234,  5.28319725, ...,  4.22561067,\n",
       "          6.80798215,  4.8392517 ],\n",
       "        ...,\n",
       "        [10.16003145,  8.91877752,  8.1218631 , ...,  6.61033506,\n",
       "         10.62911264,  7.42071031],\n",
       "        [10.23184927,  9.03993906,  8.25133016, ...,  6.7666796 ,\n",
       "         10.72920653,  7.50025862],\n",
       "        [ 9.62143119,  8.40258483,  7.61509436, ...,  6.13128369,\n",
       "         10.09148191,  6.91356681]]),\n",
       " array([[ 7.16934619,  6.4808141 ,  7.46428527, ...,  5.02520661,\n",
       "          6.04542406,  3.72875747],\n",
       "        [ 6.84460668,  6.00520849,  6.99326245, ...,  4.52420064,\n",
       "          5.59483353,  3.32821814],\n",
       "        [ 6.69661225,  5.97951423,  6.95681381, ...,  4.54931122,\n",
       "          5.53608338,  3.26344079],\n",
       "        ...,\n",
       "        [10.54512104,  8.53442524,  9.82485897, ...,  6.85595865,\n",
       "          8.53766989,  5.93577153],\n",
       "        [10.63908129,  8.66220912,  9.97781219, ...,  7.026395  ,\n",
       "          8.66152184,  5.9996588 ],\n",
       "        [10.00589979,  8.03418658,  9.32111303, ...,  6.38645926,\n",
       "          8.02109643,  5.42237289]])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_K = [cdist(X_iris, centrds, 'euclidean') for centrds in centroids]\n",
    "D_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cIdx = [np.argmin(D, axis=1) for D in D_K]\n",
    "dist = [np.min(D,axis=1) for D in D_K]\n",
    "avgWithinSS = [sum(d)/X_scale.shape[0] for d in dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total with-in sum of square\n",
    "wcss = [sum(d**2) for d in dist]\n",
    "tss = sum(pdist(X_scale)**2)/X_scale.shape[0]\n",
    "bss = tss-wcss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Elbow for KMeans clustering')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## elbow curve - Avg. within-cluster sum of squares\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(K, avgWithinSS, 'b*-')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Average within-cluster sum of squares')\n",
    "plt.title('Elbow for KMeans clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Elbow for KMeans clustering')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## elbow curve - percentage of variance explained\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(K, bss/tss*100, 'b*-')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of variance explained')\n",
    "plt.ylabel('Percentage of variance explained')\n",
    "plt.title('Elbow for KMeans clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eigen Values\n",
      " [1.57253666 0.03783334]\n",
      "\n",
      "Eigen Vectors\n",
      " [[ 0.75530088 -0.6553782 ]\n",
      " [ 0.6553782   0.75530088]]\n"
     ]
    }
   ],
   "source": [
    "## Calculation of eigenvectors & eigenvalues\n",
    "import numpy as np\n",
    "w,v = np.linalg.eig(np.array([[0.91335, 0.75969],[0.75969, 0.69702]]))\n",
    "print(\"\\nEigen Values\\n\", w)\n",
    "print(\"\\nEigen Vectors\\n\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means_fit = KMeans(n_clusters=4, max_iter=300)\n",
    "k_means_fit.fit(X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.13597027,  0.09659843,  0.996271  ,  1.01717187],\n",
       "       [-0.73463631,  1.45201075, -1.29704352, -1.21071997],\n",
       "       [-0.05021989, -0.88029181,  0.34753171,  0.28206327],\n",
       "       [-1.34320731,  0.12656736, -1.31407576, -1.30726051]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means_fit.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Means Clustering - Confusion Matrix\n",
      "\n",
      " Predicted         0   1   2   3\n",
      "Actuall                        \n",
      "Iris-setosa       0  27   0  23\n",
      "Iris-versicolor  11   0  39   0\n",
      "Iris-virginica   36   0  14   0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nK-Means Clustering - Confusion Matrix\\n\\n\",\n",
    "     pd.crosstab(y_iris, k_means_fit.labels_, rownames = ['Actuall'], colnames=[\"Predicted\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Silhouette-score: 0.366\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSilhouette-score: %0.3f\" % silhouette_score(X_iris, k_means_fit.labels_, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K value 2 , Silhouette-score: 0.681\n",
      "For K value 3 , Silhouette-score: 0.553\n",
      "For K value 4 , Silhouette-score: 0.498\n",
      "For K value 5 , Silhouette-score: 0.491\n",
      "For K value 6 , Silhouette-score: 0.369\n",
      "For K value 7 , Silhouette-score: 0.351\n",
      "For K value 8 , Silhouette-score: 0.363\n",
      "For K value 9 , Silhouette-score: 0.354\n"
     ]
    }
   ],
   "source": [
    "for k in range(2, 10):\n",
    "    k_means_fitk = KMeans(n_clusters=k, max_iter=300)\n",
    "    k_means_fitk.fit(X_iris)\n",
    "    print(\"For K value\", k, \", Silhouette-score: %0.3f\"%\n",
    "          silhouette_score(X_iris, k_means_fitk.labels_, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hierarchical Clustering\n",
    "## k-means는 비계층적 방법이라고도 하며, 분석속도가 빠르고 군집을 형성하면서 유연하게 다른 군집으로 다시 \n",
    "## 재군집화가 가능한 반면, 계층적 군집분석은 한번 어떤 군집에 속한 개체는 분석과정에서 다른 군집과 \n",
    "## 더 가깝게 계산되어도 다른 군집화가 허용되지 않는 방법이다. 속도로 오래 걸린다.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-deep')\n",
    "import matplotlib.cm\n",
    "cmap = matplotlib.cm.get_cmap('plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading in data\n",
    "data = pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/Mall_Customers.csv\", \n",
    "                   encoding=\"UTF-8-sig\")\n",
    "X = data.iloc[:, [3,4]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dendrogram to choose number of clusters (k)\n",
    "import scipy.cluster.hierarchy as sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['Hancom Gothic Regular'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "z = sch.linkage(X, method = 'ward')\n",
    "dendrogram = sch.dendrogram(z)\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Customers')\n",
    "plt.ylabel('ward distances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "# Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "hc = AgglomerativeClustering(n_clusters=k, affinity=\"euclidean\", linkage='ward')\n",
    "y_hc=hc.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [('Cluster' + str(i+1)) for i in range(k)]\n",
    "plt.figure(2)\n",
    "for i in range(k):\n",
    "    plt.scatter(X[y_hc == i, 0], X[y_hc == i, 1], s =20, c = cmap(i/k), label = labels[i])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Spending score')\n",
    "plt.title('HC cluster plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 17 DBSCAN\n",
    "## 17.1 핵심 개념\n",
    "## 밀도기반 클러스터링 기법 \n",
    "## 이 방법은 케이스가 집중되어 있는 밀도에 초점을 두어 밀도가 높은 그룹을 클러스터링 하는 방식이다.\n",
    "## 중심점을 기준으로 특정한 반경 이내에 케이스가 n개 이상 있을 경우 하나의 군집을 형성하는 알고리즘\n",
    "## epsilon 근접 이웃점을 찾기 위해 정의 내려야 하는 반경 거리 \n",
    "## minpts(최소점) 하나의 군집을 형성하기 위해 필요한 최소 케이스 \n",
    "## core point 엡실런 반경 내에 최소점 이상을 갖는 점 \n",
    "## Border point core point의 엡실런 반경 내에 있으나 그 자체로는 최소점을 갖지 못하는 점 \n",
    "## Noise point core point도 아니고 border point도 아닌 점 \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(\"C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/iris.csv\", encoding=\"UTF-8-sig\")\n",
    "iris_data = iris[iris.columns[0:4]]\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DBSCAN 모델 적용 \n",
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, metric='euclidean', min_samples=5)\n",
    "dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
       "        1,  1,  1, -1, -1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1, -1,\n",
       "        1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.fit(iris_data)\n",
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predict\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=dbscan.fit_predict(iris_data)\n",
    "pred=pd.DataFrame(pred)\n",
    "pred.columns=['predict']\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        class  predict\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa        0\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa        0\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa        0\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa        0\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa        0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_data = pd.concat([iris,pred],axis=1)\n",
    "match_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predict</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-setosa</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predict          -1   0   1\n",
       "class                      \n",
       "Iris-setosa       1  49   0\n",
       "Iris-versicolor   6   0  44\n",
       "Iris-virginica   10   0  40"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross = pd.crosstab(match_data['class'], match_data['predict'])\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2).fit(iris_data)\n",
    "pca_2d = pca.transform(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0, pca_2d.shape[0]):\n",
    "    if dbscan.labels_[i] == 0:\n",
    "        c1 = plt.scatter(pca_2d[i,0], pca_2d[i,1], c='r', marker='+')\n",
    "    elif dbscan.labels_[i] == 1:\n",
    "        c2 = plt.scatter(pca_2d[i,0], pca_2d[i,1], c='g', marker='o')\n",
    "    elif dbscan.labels_[i] == -1:\n",
    "        c3 = plt.scatter(pca_2d[i,0], pca_2d[i,1], c='b', marker='*')\n",
    "plt.legend([c1, c2, c3], ['Cluster 1', 'Cluster 2', 'Noise'])\n",
    "plt.title('DBSCAN finds 2 clusters and noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section18 연관규칙분석\n",
    "## 연관규칙은 Apriori Algorithm이라고도 하며, 대용량의 트랜잭션 데이터로부터 X면 Y이다 라는 식의 \n",
    "## 연관관계를 발견하는 기법이다. 장바구니 분석,\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shrimp</th>\n",
       "      <th>almonds</th>\n",
       "      <th>avocado</th>\n",
       "      <th>vegetables mix</th>\n",
       "      <th>green grapes</th>\n",
       "      <th>whole weat flour</th>\n",
       "      <th>yams</th>\n",
       "      <th>cottage cheese</th>\n",
       "      <th>energy drink</th>\n",
       "      <th>tomato juice</th>\n",
       "      <th>low fat yogurt</th>\n",
       "      <th>green tea</th>\n",
       "      <th>honey</th>\n",
       "      <th>salad</th>\n",
       "      <th>mineral water</th>\n",
       "      <th>salmon</th>\n",
       "      <th>antioxydant juice</th>\n",
       "      <th>frozen smoothie</th>\n",
       "      <th>spinach</th>\n",
       "      <th>olive oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>burgers</td>\n",
       "      <td>meatballs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chutney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turkey</td>\n",
       "      <td>avocado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mineral water</td>\n",
       "      <td>milk</td>\n",
       "      <td>energy bar</td>\n",
       "      <td>whole wheat rice</td>\n",
       "      <td>green tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shrimp    almonds     avocado    vegetables mix green grapes  \\\n",
       "0         burgers  meatballs        eggs               NaN          NaN   \n",
       "1         chutney        NaN         NaN               NaN          NaN   \n",
       "2          turkey    avocado         NaN               NaN          NaN   \n",
       "3   mineral water       milk  energy bar  whole wheat rice    green tea   \n",
       "4  low fat yogurt        NaN         NaN               NaN          NaN   \n",
       "\n",
       "  whole weat flour yams cottage cheese energy drink tomato juice  \\\n",
       "0              NaN  NaN            NaN          NaN          NaN   \n",
       "1              NaN  NaN            NaN          NaN          NaN   \n",
       "2              NaN  NaN            NaN          NaN          NaN   \n",
       "3              NaN  NaN            NaN          NaN          NaN   \n",
       "4              NaN  NaN            NaN          NaN          NaN   \n",
       "\n",
       "  low fat yogurt green tea honey salad mineral water salmon antioxydant juice  \\\n",
       "0            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "1            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "2            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "3            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "4            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "\n",
       "  frozen smoothie spinach  olive oil  \n",
       "0             NaN     NaN        NaN  \n",
       "1             NaN     NaN        NaN  \n",
       "2             NaN     NaN        NaN  \n",
       "3             NaN     NaN        NaN  \n",
       "4             NaN     NaN        NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/MJ/Desktop/새 폴더 (2)/[2] 교재 data/Market_Basket.csv',\n",
    "                  encoding='UTF-8-sig')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7500 entries, 0 to 7499\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   shrimp             7500 non-null   object \n",
      " 1   almonds            5746 non-null   object \n",
      " 2   avocado            4388 non-null   object \n",
      " 3   vegetables mix     3344 non-null   object \n",
      " 4   green grapes       2528 non-null   object \n",
      " 5   whole weat flour   1863 non-null   object \n",
      " 6   yams               1368 non-null   object \n",
      " 7   cottage cheese     980 non-null    object \n",
      " 8   energy drink       653 non-null    object \n",
      " 9   tomato juice       394 non-null    object \n",
      " 10  low fat yogurt     255 non-null    object \n",
      " 11  green tea          153 non-null    object \n",
      " 12  honey              86 non-null     object \n",
      " 13  salad              46 non-null     object \n",
      " 14  mineral water      24 non-null     object \n",
      " 15  salmon             7 non-null      object \n",
      " 16  antioxydant juice  3 non-null      object \n",
      " 17  frozen smoothie    3 non-null      object \n",
      " 18  spinach            2 non-null      object \n",
      " 19  olive oil          0 non-null      float64\n",
      "dtypes: float64(1), object(19)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-2bb67aeaab05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtransactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "transactions = []\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[1]-data.isnull().sum(axis=1)[i]):\n",
    "        transactions.append([str(data[j][i])])\n",
    "                            \n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shrimp</th>\n",
       "      <th>almonds</th>\n",
       "      <th>avocado</th>\n",
       "      <th>vegetables mix</th>\n",
       "      <th>green grapes</th>\n",
       "      <th>whole weat flour</th>\n",
       "      <th>yams</th>\n",
       "      <th>cottage cheese</th>\n",
       "      <th>energy drink</th>\n",
       "      <th>tomato juice</th>\n",
       "      <th>low fat yogurt</th>\n",
       "      <th>green tea</th>\n",
       "      <th>honey</th>\n",
       "      <th>salad</th>\n",
       "      <th>mineral water</th>\n",
       "      <th>salmon</th>\n",
       "      <th>antioxydant juice</th>\n",
       "      <th>frozen smoothie</th>\n",
       "      <th>spinach</th>\n",
       "      <th>olive oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>burgers</td>\n",
       "      <td>meatballs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chutney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turkey</td>\n",
       "      <td>avocado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mineral water</td>\n",
       "      <td>milk</td>\n",
       "      <td>energy bar</td>\n",
       "      <td>whole wheat rice</td>\n",
       "      <td>green tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shrimp    almonds     avocado    vegetables mix green grapes  \\\n",
       "0         burgers  meatballs        eggs               NaN          NaN   \n",
       "1         chutney        NaN         NaN               NaN          NaN   \n",
       "2          turkey    avocado         NaN               NaN          NaN   \n",
       "3   mineral water       milk  energy bar  whole wheat rice    green tea   \n",
       "4  low fat yogurt        NaN         NaN               NaN          NaN   \n",
       "\n",
       "  whole weat flour yams cottage cheese energy drink tomato juice  \\\n",
       "0              NaN  NaN            NaN          NaN          NaN   \n",
       "1              NaN  NaN            NaN          NaN          NaN   \n",
       "2              NaN  NaN            NaN          NaN          NaN   \n",
       "3              NaN  NaN            NaN          NaN          NaN   \n",
       "4              NaN  NaN            NaN          NaN          NaN   \n",
       "\n",
       "  low fat yogurt green tea honey salad mineral water salmon antioxydant juice  \\\n",
       "0            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "1            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "2            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "3            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "4            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "\n",
       "  frozen smoothie spinach  olive oil  \n",
       "0             NaN     NaN        NaN  \n",
       "1             NaN     NaN        NaN  \n",
       "2             NaN     NaN        NaN  \n",
       "3             NaN     NaN        NaN  \n",
       "4             NaN     NaN        NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: apyori in c:\\users\\mj\\anaconda3\\lib\\site-packages (1.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install apyori\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\mj\\anaconda3\\lib\\site-packages (22.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = apriori(transactions, min_support = 0.015, min_confidence=0.2, min_lift=1, min_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = list(rules)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('apriori_result.csv')\n",
    "print(df.iloc[6:19][['items', 'support']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar=(df.iloc[1:74]['items'])\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(9,6))\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(ar)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, font_size=16, with_labels=False, edge_color='green',\n",
    "       node_size=800, node_color=['red', 'green', 'blue', 'cyan', 'orange', 'magenta'])\n",
    "for p in pos:\n",
    "    pos[p][1] += 0.07\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
